{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Importing necessary libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import RFE","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/cardiotocographic/Cardiotocographic.csv')\ndf.head()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"    LB        AC   FM        UC        DL   DS   DP  ASTV  MSTV  ALTV  ...  \\\n0  120  0.000000  0.0  0.000000  0.000000  0.0  0.0    73   0.5    43  ...   \n1  132  0.006380  0.0  0.006380  0.003190  0.0  0.0    17   2.1     0  ...   \n2  133  0.003322  0.0  0.008306  0.003322  0.0  0.0    16   2.1     0  ...   \n3  134  0.002561  0.0  0.007682  0.002561  0.0  0.0    16   2.4     0  ...   \n4  132  0.006515  0.0  0.008143  0.000000  0.0  0.0    16   2.4     0  ...   \n\n   Min  Max  Nmax  Nzeros  Mode  Mean  Median  Variance  Tendency  NSP  \n0   62  126     2       0   120   137     121        73         1    2  \n1   68  198     6       1   141   136     140        12         0    1  \n2   68  198     5       1   141   135     138        13         0    1  \n3   53  170    11       0   137   134     137        13         1    1  \n4   53  170     9       0   137   136     138        11         1    1  \n\n[5 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LB</th>\n      <th>AC</th>\n      <th>FM</th>\n      <th>UC</th>\n      <th>DL</th>\n      <th>DS</th>\n      <th>DP</th>\n      <th>ASTV</th>\n      <th>MSTV</th>\n      <th>ALTV</th>\n      <th>...</th>\n      <th>Min</th>\n      <th>Max</th>\n      <th>Nmax</th>\n      <th>Nzeros</th>\n      <th>Mode</th>\n      <th>Mean</th>\n      <th>Median</th>\n      <th>Variance</th>\n      <th>Tendency</th>\n      <th>NSP</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>120</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>73</td>\n      <td>0.5</td>\n      <td>43</td>\n      <td>...</td>\n      <td>62</td>\n      <td>126</td>\n      <td>2</td>\n      <td>0</td>\n      <td>120</td>\n      <td>137</td>\n      <td>121</td>\n      <td>73</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>132</td>\n      <td>0.006380</td>\n      <td>0.0</td>\n      <td>0.006380</td>\n      <td>0.003190</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>17</td>\n      <td>2.1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>68</td>\n      <td>198</td>\n      <td>6</td>\n      <td>1</td>\n      <td>141</td>\n      <td>136</td>\n      <td>140</td>\n      <td>12</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>133</td>\n      <td>0.003322</td>\n      <td>0.0</td>\n      <td>0.008306</td>\n      <td>0.003322</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>16</td>\n      <td>2.1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>68</td>\n      <td>198</td>\n      <td>5</td>\n      <td>1</td>\n      <td>141</td>\n      <td>135</td>\n      <td>138</td>\n      <td>13</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>134</td>\n      <td>0.002561</td>\n      <td>0.0</td>\n      <td>0.007682</td>\n      <td>0.002561</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>16</td>\n      <td>2.4</td>\n      <td>0</td>\n      <td>...</td>\n      <td>53</td>\n      <td>170</td>\n      <td>11</td>\n      <td>0</td>\n      <td>137</td>\n      <td>134</td>\n      <td>137</td>\n      <td>13</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>132</td>\n      <td>0.006515</td>\n      <td>0.0</td>\n      <td>0.008143</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>16</td>\n      <td>2.4</td>\n      <td>0</td>\n      <td>...</td>\n      <td>53</td>\n      <td>170</td>\n      <td>9</td>\n      <td>0</td>\n      <td>137</td>\n      <td>136</td>\n      <td>138</td>\n      <td>11</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 22 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Shape of the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"(2126, 22)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Checking if there are any missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"LB          0\nAC          0\nFM          0\nUC          0\nDL          0\nDS          0\nDP          0\nASTV        0\nMSTV        0\nALTV        0\nMLTV        0\nWidth       0\nMin         0\nMax         0\nNmax        0\nNzeros      0\nMode        0\nMean        0\nMedian      0\nVariance    0\nTendency    0\nNSP         0\ndtype: int64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Splitting into explanatory and response variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.DataFrame(df.iloc[:, 0:21])\ny = df['NSP']","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Splitting into train and test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 2)","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<br/>\n\n## Random Forest Classifier with all variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier()\nmodel = rf.fit(X_train, y_train)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = rf.predict(X_test)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf.score(X_test, y_test)","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"0.9436619718309859"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"<br/>\n\n## Without using RFE\nwe can also choose the best variables with 'feature_importances_'. Values close to 1 are the best suited variables for the model. But removing one variable can change the significance of other variables. That's why there's always a risk."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(rf.feature_importances_)","execution_count":10,"outputs":[{"output_type":"stream","text":"[0.03633204 0.04902307 0.01988178 0.04638578 0.00883794 0.00132376\n 0.05195355 0.13536727 0.11824712 0.11486208 0.04340697 0.03488225\n 0.0402299  0.02960616 0.01868307 0.00474329 0.05568222 0.09811449\n 0.053578   0.0325775  0.00628176]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"<br/>\n\n\n## So we will go for the less risky solution : The Mighty RFE\nstep = 10 - To speed up the RFE process, we can set the 'step' parameter to RFE. And the 10 means on each iterations 10 least important features will be dropped out."},{"metadata":{"trusted":true},"cell_type":"code","source":"rfe = RFE(estimator = RandomForestClassifier(), n_features_to_select = 18, step = 10, verbose = 1)\nrfe.fit(X_train, y_train)","execution_count":11,"outputs":[{"output_type":"stream","text":"Fitting estimator with 21 features.\n","name":"stdout"},{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"RFE(estimator=RandomForestClassifier(), n_features_to_select=18, step=10,\n    verbose=1)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y1_pred = rfe.predict(X_test)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfe.score(X_test, y_test)","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"0.9483568075117371"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"##### Conclussion:  It's a quite improvement from the first model."},{"metadata":{},"cell_type":"markdown","source":"<br/>\n\n## Columns RFE choose for the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X.columns[rfe.support_])","execution_count":14,"outputs":[{"output_type":"stream","text":"Index(['LB', 'AC', 'FM', 'UC', 'DL', 'DP', 'ASTV', 'MSTV', 'ALTV', 'MLTV',\n       'Width', 'Min', 'Max', 'Nmax', 'Mode', 'Mean', 'Median', 'Variance'],\n      dtype='object')\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"<br/>\n<br/>\n\n## Note:\nI discussed RFE more in another [notebook](https://www.kaggle.com/galibce003/confused-with-too-many-features-solution-is-here).\n\n<br/>\n<br/>\n\n## Feel free to share your thoughts and if you find it helpful, please upvote. Thanks!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}