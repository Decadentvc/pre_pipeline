{"cells":[{"metadata":{},"cell_type":"markdown","source":"# PREDICTING A PULSAR STAR\n\nMachine learning tools are now being used to automatically label pulsar candidates to facilitate rapid analysis. Classification systems in particular are being widely adopted, which treat the candidate data sets as binary classification problems. Here the legitimate pulsar examples are a minority positive class, and spurious examples the majority negative class.\n\nThe data set shared here contains 16,259 spurious examples caused by RFI/noise, and 1,639 real pulsar examples. These examples have all been checked by human annotators.\n\nEach row lists the variables first, and the class label is the final entry. The class labels used are 0 (negative) and 1 (positive).\n\nMachine Learning algorithms used to predict the target in the following dataset are\n\n1-Logistic Regression\n\n2-Random Forest Classifier \n\n3-Support Vector Classification\n\nthe github repo to this same dataset can be found here https://github.com/sid26ranjan/pulsar-star\n\nalso check out my other kernels and github repos https://github.com/sid26ranjan"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.read_csv('../input/predicting-a-pulsar-star/pulsar_stars.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### SOME BASIC INFORMATION ABOUT THE DATA SET"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### TARGET  CLASS"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['target_class'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data['target_class'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data['target_class']==1].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data['target_class']==0].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Attribute Information:\n\nEach candidate is described by 8 continuous variables, and a single class variable. \n\nThe first four are simple statistics obtained from the integrated pulse profile (folded profile).\n\nThis is an array of continuous variables that describe a longitude-resolved version of the signal that has been averaged in both time and frequency .\n\nThe remaining four variables are similarly obtained from the DM-SNR curve . These are summarised below:\n\nMean of the integrated profile.\n\nStandard deviation of the integrated profile.\n\nExcess kurtosis of the integrated profile.\n\nSkewness of the integrated profile.\n\nMean of the DM-SNR curve.\n\nStandard deviation of the DM-SNR curve.\n\nExcess kurtosis of the DM-SNR curve.\n\nSkewness of the DM-SNR curve.\n\nClass"},{"metadata":{},"cell_type":"markdown","source":"###### CORRELATION BETWEEN THE FEATURES"},{"metadata":{"trusted":true},"cell_type":"code","source":"correlation=data.corr()\nfig = plt.figure(figsize=(12, 10))\n\nsns.heatmap(correlation, annot=True, center=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=data['target_class']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=data.drop(['target_class'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### LOGISTIC REGRESSION:"},{"metadata":{"trusted":true},"cell_type":"code","source":"model=LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### RANDOM FOREST CLASSIFIER :"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc = RandomForestClassifier(n_estimators=200)\nrfc.fit(X_train, y_train)\npred_rfc = rfc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, pred_rfc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### SUPPORT VECTOR CLASSIFICATION :"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = SVC() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.fit(X_train, y_train) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_svc=clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, pred_svc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Accuracy from Support Vector Classification is '+str(clf.score(X_test,y_test)*100)+\"%\")\nprint('Accuracy from Random forest classifier is '+str(rfc.score(X_test,y_test)*100)+'%')\nprint('Accuracy from Logistic regression is '+str(model.score(X_test,y_test)*100)+'%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**If you find this kernel useful please upvote.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}