{"cells":[{"metadata":{},"cell_type":"markdown","source":"\n\n# Adult Income Classification"},{"metadata":{},"cell_type":"markdown","source":"## Classification Project"},{"metadata":{},"cell_type":"markdown","source":"### Contents\n\n### 1. Introduction\n\n### 2. General View of the Data\n\n### 3. Data Cleaning\n\n### 4. Exploring the Data\n\n### 5.Models\n\n### 6.Conclusions "},{"metadata":{},"cell_type":"markdown","source":"## 1. Introduction"},{"metadata":{},"cell_type":"markdown","source":"Our aim in this project is to predict classification by income.The prediction task is to determine whether a person makes over $50K a year.This data used was extracted from the 1994 Census bureau database by Ronny Kohavi and Barry Becker.A set of reasonably clean records was extracted using following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1) && (HRSWK>0)).\n"},{"metadata":{},"cell_type":"markdown","source":"## 2. General View of the Data"},{"metadata":{},"cell_type":"markdown","source":" **Columns**\n* age \n* workclass \n* fnlwgt \n* education \n* education-num \n* marital-status \n* occupation\n* relationship \n* race \n* sex \n* capital-gain \n* capital-loss \n* hours-per-week \n* native-country \n* income "},{"metadata":{},"cell_type":"markdown","source":" __Categorical Variables__\n \n \n * sex \n * race\n * income\n * workclass         \n * education\n * occupation\n * relationship \n * marital-status    \n * native-country          \n    \n  __Continuous Variables__\n  \n\n * age\n * fnlwgt \n * capital-loss\n * capital-gain\n * education-num \n * hours-per-week"},{"metadata":{},"cell_type":"markdown","source":"### Let's start by importing libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Viewing Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/adult-census-income/adult.csv\")\ndf.columns = df.columns.str.replace(\" \",\"\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Data Cleaning"},{"metadata":{},"cell_type":"markdown","source":"### Is there missing data ?"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df.isna().values.any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Is there problematic values ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"for sutun_adi in df.columns:\n    print(\"{} sütundaki benzersiz değerler\".format(sutun_adi))\n    print(\"{}\".format(df[sutun_adi].unique()),\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"native.country\"] = df[\"native.country\"].apply(str.strip).replace(\"?\",np.nan)\nliste_1 =df[\"native.country\"]\n\nfor i in range(0,len(liste_1)):\n    if pd.isnull(liste_1[i]):\n        liste_1[i] = liste_1[i-1]\n        \ndf[\"native.country\"].unique()        \n                ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"occupation\"] = df[\"occupation\"].apply(str.strip).replace(\"?\",np.nan)\n\nliste_2 =df[\"occupation\"]\n\nfor i in range(0,len(liste_2)):\n    if pd.isnull(liste_2[i]):\n        liste_2[i] = liste_2[i+1]\n        \ndf[\"occupation\"].unique() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"workclass\"] = df[\"workclass\"].apply(str.strip).replace(\"?\",np.nan)\nliste_3 =df[\"workclass\"]\n\nfor i in range(0,len(liste_3)):\n    if pd.isnull(liste_3[i]):\n        liste_3[i] = liste_3[i+1]\n        \ndf[\"workclass\"].unique() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### And last how abaout the outliers ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(19,12))\n\n\nnum_feat = df.select_dtypes(include=['int64']).columns\n\nfor i in range(6):\n    plt.subplot(2,3,i+1)\n    plt.boxplot(df[num_feat[i]])\n    plt.title(num_feat[i],color=\"g\",fontsize=20)\n    plt.yticks(fontsize=14)\n    plt.xticks(fontsize=14)\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's get rid of the outliers by winsorization"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats.mstats import winsorize\ndf[\"age\"]           = winsorize(df[\"age\"],(0,0.15))\ndf[\"fnlwgt\"]        = winsorize(df[\"fnlwgt\"],(0,0.15))\ndf[\"capital.gain\"]  = winsorize(df[\"capital.gain\"],(0,0.099))\ndf[\"capital.loss\"]  = winsorize(df[\"capital.loss\"],(0,0.099))\ndf[\"hours.per.week\"]= winsorize(df[\"hours.per.week\"],(0.12,0.18))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (25,7)\n\nbaslik_font = {'family':'arial','color':'purple','weight':'bold','size':25}\n\ncol_list=['age',\"fnlwgt\",'capital.gain', 'capital.loss', 'hours.per.week']\n\nfor i in range(5):\n    plt.subplot(1,5,i+1)\n    plt.boxplot(df[col_list[i]])\n    plt.title(col_list[i],fontdict=baslik_font)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Exploring the Data"},{"metadata":{},"cell_type":"markdown","source":"### Continuous Variables's Distribution Graphs about Income"},{"metadata":{"trusted":true},"cell_type":"code","source":"con_var=['age', 'fnlwgt', 'education.num','hours.per.week']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nplt.subplot(221)\n\ni=0\nfor x in con_var:\n    plt.subplot(2, 2, i+1)\n    i += 1\n    ax1=sns.kdeplot(df[df['income'] == '<=50K'][x], shade=True,label=\"income <=50K\")\n    sns.kdeplot(df[df['income'] == '>50K'][x], shade=False,label=\"income   >50K\", ax=ax1)\n    plt.title(x,fontsize=15)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Categorical Variables's Graphs by Count Plot about İncome"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,7))\n\ndeg=[\"race\",\"sex\"]\n\nfor i in range(2):\n    plt.subplot(1,2,i+1)\n    sns.countplot(x=deg[i],data=df,hue='income')\n    plt.xlabel(deg[i],color=\"darkorange\",fontsize=18)\n    plt.ylabel(\"Count\",color=\"darkorange\",fontsize=18)\n    plt.yticks(fontsize=13)\n    plt.xticks(rotation=90,fontsize=13)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Of course we are against racial and gender discrimination :) "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,7))\n\ndeg=[\"occupation\",\"hours.per.week\"]\n\nfor i in range(2):\n    plt.subplot(1,2,i+1)\n    sns.countplot(x=deg[i],data=df,hue=\"income\")\n    plt.xlabel(deg[i],color=\"darkorange\",fontsize=20)\n    plt.ylabel(\"Count\",color=\"darkorange\",fontsize=20)\n    plt.yticks(fontsize=13)\n    plt.xticks(rotation=90,fontsize=13)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,7))\n\ndeg=[\"education\",\"education.num\"]\n\nfor i in range(2):\n    plt.subplot(1,2,i+1)\n    sns.countplot(x=deg[i],data=df,hue=\"income\")\n    plt.xlabel(deg[i],color=\"darkorange\",fontsize=20)\n    plt.ylabel(\"Count\",color=\"darkorange\",fontsize=20)\n    plt.yticks(fontsize=13)\n    plt.xticks(rotation=90,fontsize=13)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,7))\n\ndeg = [\"relationship\",\"marital.status\"]\n\nfor i in range(2):\n    plt.subplot(1,2,i+1)\n    sns.countplot(x=deg[i],data=df,hue=\"income\")\n    plt.xlabel(deg[i],color=\"darkorange\",fontsize=18)\n    plt.ylabel(\"Count\",color=\"darkorange\",fontsize=18)\n    plt.xticks(rotation=90,fontsize=15)\n    plt.yticks(fontsize=15)\n\nplt.show()    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(13,10))\nsns.countplot(x=df[\"native.country\"],data=df)\nplt.xlabel(\"native.country\",color=\"purple\",fontsize=20)\nplt.ylabel(\"Count\",color=\"purple\",fontsize=20)\nplt.xticks(rotation=90,fontsize=15)\nplt.yticks(fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Correlation Matrix between Numerical Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"list=['age','education.num',\"hours.per.week\",\"fnlwgt\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,7))\nsns.heatmap(df[list].corr(),annot=True, fmt = \".2f\", cmap = \"YlGnBu\")\nplt.title(\"Correlation Matrix\",color=\"darkblue\",fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"woman?\"]  = df.sex.replace({\"Female\":1,\"Male\":0})\ndf[\"income_\"] = df.income.replace({\"<=50K\":0,\">50K\":1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = pd.get_dummies(df['workclass'])\ndf2 = pd.get_dummies(df[\"education\"])\ndf3 = pd.get_dummies(df[\"marital.status\"])\ndf4 = pd.get_dummies(df[\"occupation\"])\ndf5 = pd.get_dummies(df[\"relationship\"])\ndf6 = pd.get_dummies(df[\"race\"])\ndf7 = pd.get_dummies(df[\"native.country\"])\n\ndf  = pd.concat([df,df1,df2,df3,df4,df5,df6,df7],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6.Models"},{"metadata":{},"cell_type":"markdown","source":"### Imbalanced Data"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(7,5))\nsns.countplot(df[\"income_\"])\nplt.xlabel(\"İncome Case\",fontsize=15)\nplt.ylabel(\"Count\",fontsize=15)\nprint(\">50K  rate : %{:.2f}\".format(sum(df[\"income_\"])/len(df[\"income_\"])*100))\nprint(\"<=50K rate : %{:.2f}\".format((len(df[\"income_\"])-sum(df[\"income_\"]))/len(df[\"income_\"])*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__%24.08 of the data in the data set is classified as positive.Therefore we can say that the data set is not balanced.__"},{"metadata":{},"cell_type":"markdown","source":"### Model 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df[\"income_\"]\nX = df[['age','hours.per.week',\"fnlwgt\",\n       'woman?','Federal-gov', 'Local-gov',\n       'Never-worked', 'Private', 'Self-emp-inc', 'Self-emp-not-inc',\n       'State-gov', 'Without-pay', 'Federal-gov', 'Local-gov', 'Never-worked',\n       'Private', 'Self-emp-inc','Self-emp-not-inc', 'State-gov', 'Without-pay', '10th', '11th',\n       '12th', '1st-4th', '5th-6th', '7th-8th', '9th', 'Assoc-acdm',\n       'Assoc-voc', 'Bachelors', 'Doctorate', 'HS-grad', 'Masters',\n       'Preschool', 'Prof-school', 'Some-college', 'Adm-clerical',\n       'Armed-Forces', 'Craft-repair', 'Exec-managerial', 'Farming-fishing',\n       'Handlers-cleaners', 'Machine-op-inspct', 'Other-service',\n       'Priv-house-serv', 'Prof-specialty', 'Protective-serv', 'Sales',\n       'Tech-support', 'Transport-moving', 'Husband', 'Not-in-family',\n       'Other-relative', 'Own-child', 'Unmarried', 'Wife',\n       'Amer-Indian-Eskimo','Asian-Pac-Islander', 'Black', 'Other', 'White', 'Cambodia',\n       'Canada', 'China', 'Columbia', 'Cuba', 'Dominican-Republic', 'Ecuador',\n       'El-Salvador', 'England', 'France', 'Germany', 'Greece', 'Guatemala',\n       'Haiti', 'Holand-Netherlands', 'Honduras', 'Hong', 'Hungary', 'India',\n       'Iran', 'Ireland', 'Italy', 'Jamaica', 'Japan', 'Laos', 'Mexico',\n       'Nicaragua', 'Outlying-US(Guam-USVI-etc)', 'Peru', 'Philippines',\n       'Poland', 'Portugal', 'Puerto-Rico', 'Scotland', 'South', 'Taiwan',\n       'Thailand', 'Trinadad&Tobago', 'United-States', 'Vietnam',\n       'Yugoslavia']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import f1_score\n\nmodel_1_predict_model = LogisticRegression(penalty='l2')\nmodel_1_predict_model.fit(X_train,y_train)\n\npredict_train_1 = model_1_predict_model.predict(X_train)\npredict_test_1  = model_1_predict_model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report,precision_recall_fscore_support\n\nprint(\"Model's Accuracy values       :\",model_1_predict_model.score(X_test,y_test))\nprint(\"Model's Train f1_score values :\",f1_score(y_train,predict_train_1))\nprint(\"Model's Test  f1_score values :\",f1_score(y_test,predict_test_1),\"\\n\")\n\nprint(classification_report(y_test,predict_test_1),\"\\n\")\n\nmetrics_1 =precision_recall_fscore_support(y_test,predict_test_1)\n\nprint(\"Precision:\",metrics_1[0])\nprint(\"Recall   :\",metrics_1[1])\nprint(\"F1 Skoru :\",metrics_1[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve, roc_auc_score\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_1_predict_test_proba = model_1_predict_model.predict_proba(X_test)[:,1]\n\nfpr, tpr, thresholds  = roc_curve(y_test,model_1_predict_test_proba )\n\nconfusion_matrix_test = confusion_matrix(y_test,predict_test_1)\n\nplt.figure(figsize=(15,7))\nplt.subplot(1,2,1)\nsns.heatmap(confusion_matrix_test,annot=True,cmap=\"YlGnBu\")\nplt.title(\"Confusion Matrix\",fontsize=15)\nplt.xlabel(\"Predicted\",fontsize=14)\nplt.ylabel(\"Actual\",fontsize=14)\n\n\n# Plot ROC curve\nplt.subplot(1,2,2)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr, tpr)\nplt.xlabel('False Positive Rate',fontsize=14)\nplt.ylabel('True Positive Rate',fontsize=14)\nplt.title('ROC Curve',fontsize=15)\nplt.show()\nprint(\"\\n\",\"\\n\",'AUC Değeri : ', roc_auc_score(y_test,model_1_predict_test_proba ))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import f1_score\n\nmodel_2_predict_model = LogisticRegression(penalty='l1')\nmodel_2_predict_model.fit(X_train,y_train)\n\npredict_train_2 = model_2_predict_model.predict(X_train)\npredict_test_2  = model_2_predict_model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report,precision_recall_fscore_support\n\nprint(\"Model's Accuracy values       :\",model_2_predict_model.score(X_test,y_test))\nprint(\"Model's Train f1_score values :\",f1_score(y_train,predict_train_2))\nprint(\"Model's Test  f1_score values :\",f1_score(y_test,predict_test_2),\"\\n\")\n\nprint(classification_report(y_test,predict_test_2),\"\\n\")\n\nmetrics_2 =precision_recall_fscore_support(y_test,predict_test_2)\n\nprint(\"Precision:\",metrics_2[0])\nprint(\"Racall   :\",metrics_2[1])\nprint(\"F1 Skoru :\",metrics_2[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve, roc_auc_score\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_2_predict_test_proba = model_2_predict_model.predict_proba(X_test)[:,1]\n\nfpr, tpr, thresholds  = roc_curve(y_test,model_2_predict_test_proba )\n\nconfusion_matrix_test_2 = confusion_matrix(y_test,predict_test_2)\n\nplt.figure(figsize=(15,7))\nplt.subplot(1,2,1)\nsns.heatmap(confusion_matrix_test,annot=True,cmap=\"YlGnBu\")\nplt.title(\"Confusion Matrix\",fontsize=15)\nplt.xlabel(\"Predicted\",fontsize=14)\nplt.ylabel(\"Actual\",fontsize=14)\n\n\n# Plot ROC curve\nplt.subplot(1,2,2)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr, tpr)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.show()\n\nprint('AUC Values : ', roc_auc_score(y_test,model_2_predict_test_proba ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom sklearn.metrics import f1_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_model(X,y):\n    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20,random_state=111,stratify=y)\n    logistic_model = LogisticRegression()\n    logistic_model.fit(X_train,y_train)\n    \n    predict_train = logistic_model.predict(X_train)\n    predict_test = logistic_model.predict(X_test)\n    confusion_matrix_train = confusion_matrix(y_train,predict_train)\n    confusion_matrix_test  = confusion_matrix(y_test,predict_test)\n    \n    print(\"Model's Accuracy values       :\",logistic_model.score(X_test,y_test))\n    print(\"Model's Train f1_score values :\",f1_score(y_train,predict_train))\n    print(\"Model's Test  f1_score values :\",f1_score(y_test,predict_test),\"\\n\")\n    print(\"TEST DATA SET\")\n    print(classification_report(y_test,predict_test))\n    \n    metrics =precision_recall_fscore_support(y_test,predict_test)\n\n    print(\"Precision:\",metrics[0])\n    print(\"Racall   :\",metrics[1])\n    print(\"F1 Skoru :\",metrics[2])\n    \n    return None\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve, roc_auc_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_graphic(X,y):\n    \n    \n    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20,random_state=111,stratify=y)\n    logistic_model = LogisticRegression()\n    logistic_model.fit(X_train,y_train)\n    \n    predict_train = logistic_model.predict(X_train)\n    predict_test = logistic_model.predict(X_test)\n    confusion_matrix_train = confusion_matrix(y_train,predict_train)\n    confusion_matrix_test  = confusion_matrix(y_test,predict_test)\n    \n    logistic_model_predict_test_proba = logistic_model.predict_proba(X_test)[:,1]\n\n    fpr, tpr, thresholds  = roc_curve(y_test,logistic_model_predict_test_proba )\n\n    confusion_matrix_test = confusion_matrix(y_test,predict_test)\n\n    plt.figure(figsize=(15,7))\n    plt.subplot(1,2,1)\n    sns.heatmap(confusion_matrix_test,annot=True,cmap=\"YlGnBu\")\n    plt.title(\"Confusion Matrix\",fontsize=15)\n    plt.xlabel(\"Predicted\",fontsize=14)\n    plt.ylabel(\"Actual\",fontsize=14)\n\n    plt.subplot(1,2,2)\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.plot(fpr, tpr)\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC Curve')\n    plt.show()\n\n    print('AUC Values : ', roc_auc_score(y_test,logistic_model_predict_test_proba))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Oversampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import resample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"positive = df[df.income_==1]\nnegative = df[df.income_==0]\n\npositive_increase = resample(positive,\n                              replace = True,\n                              n_samples = len(negative),\n                              random_state = 111)\nincrease_df = pd.concat([negative,positive_increase])\nincrease_df.income.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = increase_df[['age','fnlwgt','hours.per.week',\n       'woman?','Federal-gov', 'Local-gov',\n       'Never-worked', 'Private', 'Self-emp-inc', 'Self-emp-not-inc',\n       'State-gov', 'Without-pay', 'Federal-gov', 'Local-gov', 'Never-worked',\n       'Private', 'Self-emp-inc','Self-emp-not-inc', 'State-gov', 'Without-pay', '10th', '11th',\n       '12th', '1st-4th', '5th-6th', '7th-8th', '9th', 'Assoc-acdm',\n       'Assoc-voc', 'Bachelors', 'Doctorate', 'HS-grad', 'Masters',\n       'Preschool', 'Prof-school', 'Some-college', 'Adm-clerical',\n       'Armed-Forces', 'Craft-repair', 'Exec-managerial', 'Farming-fishing',\n       'Handlers-cleaners', 'Machine-op-inspct', 'Other-service',\n       'Priv-house-serv', 'Prof-specialty', 'Protective-serv', 'Sales',\n       'Tech-support', 'Transport-moving', 'Husband', 'Not-in-family',\n       'Other-relative', 'Own-child', 'Unmarried', 'Wife',\n       'Amer-Indian-Eskimo','Asian-Pac-Islander', 'Black', 'Other', 'White', 'Cambodia',\n       'Canada', 'China', 'Columbia', 'Cuba', 'Dominican-Republic', 'Ecuador',\n       'El-Salvador', 'England', 'France', 'Germany', 'Greece', 'Guatemala',\n       'Haiti', 'Holand-Netherlands', 'Honduras', 'Hong', 'Hungary', 'India',\n       'Iran', 'Ireland', 'Italy', 'Jamaica', 'Japan', 'Laos', 'Mexico',\n       'Nicaragua', 'Outlying-US(Guam-USVI-etc)', 'Peru', 'Philippines',\n       'Poland', 'Portugal', 'Puerto-Rico', 'Scotland', 'South', 'Taiwan',\n       'Thailand', 'Trinadad&Tobago', 'United-States', 'Vietnam',\n       'Yugoslavia']]\n\ny = increase_df[\"income_\"]\n\nmake_model(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_graphic(X,y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Undersampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import resample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"positive = df[df.income_==1]\nnegative = df[df.income_==0]\n\npositive_decrease = resample(negative,\n                              replace = True,\n                              n_samples = len(positive),\n                              random_state = 111)\ndecrease_df = pd.concat([positive,positive_decrease])\ndecrease_df.income.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = decrease_df[['age','fnlwgt', 'hours.per.week',\n       'woman?','Federal-gov', 'Local-gov',\n       'Never-worked', 'Private', 'Self-emp-inc', 'Self-emp-not-inc',\n       'State-gov', 'Without-pay', 'Federal-gov', 'Local-gov', 'Never-worked',\n       'Private', 'Self-emp-inc','Self-emp-not-inc', 'State-gov', 'Without-pay', '10th', '11th',\n       '12th', '1st-4th', '5th-6th', '7th-8th', '9th', 'Assoc-acdm',\n       'Assoc-voc', 'Bachelors', 'Doctorate', 'HS-grad', 'Masters',\n       'Preschool', 'Prof-school', 'Some-college', 'Adm-clerical',\n       'Armed-Forces', 'Craft-repair', 'Exec-managerial', 'Farming-fishing',\n       'Handlers-cleaners', 'Machine-op-inspct', 'Other-service',\n       'Priv-house-serv', 'Prof-specialty', 'Protective-serv', 'Sales',\n       'Tech-support', 'Transport-moving', 'Husband', 'Not-in-family',\n       'Other-relative', 'Own-child', 'Unmarried', 'Wife',\n       'Amer-Indian-Eskimo','Asian-Pac-Islander', 'Black', 'Other', 'White', 'Cambodia',\n       'Canada', 'China', 'Columbia', 'Cuba', 'Dominican-Republic', 'Ecuador',\n       'El-Salvador', 'England', 'France', 'Germany', 'Greece', 'Guatemala',\n       'Haiti', 'Holand-Netherlands', 'Honduras', 'Hong', 'Hungary', 'India',\n       'Iran', 'Ireland', 'Italy', 'Jamaica', 'Japan', 'Laos', 'Mexico',\n       'Nicaragua', 'Outlying-US(Guam-USVI-etc)', 'Peru', 'Philippines',\n       'Poland', 'Portugal', 'Puerto-Rico', 'Scotland', 'South', 'Taiwan',\n       'Thailand', 'Trinadad&Tobago', 'United-States', 'Vietnam',\n       'Yugoslavia']]\n\ny = decrease_df[\"income_\"]\nmake_model(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_graphic(X,y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model Smote"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df[\"income_\"]\nX = df[['age','fnlwgt','hours.per.week',\n       'woman?','Federal-gov', 'Local-gov',\n       'Never-worked', 'Private', 'Self-emp-inc', 'Self-emp-not-inc',\n       'State-gov', 'Without-pay', 'Federal-gov', 'Local-gov', 'Never-worked',\n       'Private', 'Self-emp-inc','Self-emp-not-inc', 'State-gov', 'Without-pay', '10th', '11th',\n       '12th', '1st-4th', '5th-6th', '7th-8th', '9th', 'Assoc-acdm',\n       'Assoc-voc', 'Bachelors', 'Doctorate', 'HS-grad', 'Masters',\n       'Preschool', 'Prof-school', 'Some-college', 'Adm-clerical',\n       'Armed-Forces', 'Craft-repair', 'Exec-managerial', 'Farming-fishing',\n       'Handlers-cleaners', 'Machine-op-inspct', 'Other-service',\n       'Priv-house-serv', 'Prof-specialty', 'Protective-serv', 'Sales',\n       'Tech-support', 'Transport-moving', 'Husband', 'Not-in-family',\n       'Other-relative', 'Own-child', 'Unmarried', 'Wife',\n       'Amer-Indian-Eskimo','Asian-Pac-Islander', 'Black', 'Other', 'White', 'Cambodia',\n       'Canada', 'China', 'Columbia', 'Cuba', 'Dominican-Republic', 'Ecuador',\n       'El-Salvador', 'England', 'France', 'Germany', 'Greece', 'Guatemala',\n       'Haiti', 'Holand-Netherlands', 'Honduras', 'Hong', 'Hungary', 'India',\n       'Iran', 'Ireland', 'Italy', 'Jamaica', 'Japan', 'Laos', 'Mexico',\n       'Nicaragua', 'Outlying-US(Guam-USVI-etc)', 'Peru', 'Philippines',\n       'Poland', 'Portugal', 'Puerto-Rico', 'Scotland', 'South', 'Taiwan',\n       'Thailand', 'Trinadad&Tobago', 'United-States', 'Vietnam',\n       'Yugoslavia']]\n\nsm = SMOTE(random_state=27,ratio = 1.0)\nX_smote, y_smote = sm.fit_sample(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"make_model(X_smote,y_smote)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_graphic(X_smote,y_smote)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model Adasyn"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import ADASYN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df[\"income_\"]\nX = df[['age','fnlwgt','hours.per.week',\n       'woman?','Federal-gov', 'Local-gov',\n       'Never-worked', 'Private', 'Self-emp-inc', 'Self-emp-not-inc',\n       'State-gov', 'Without-pay', 'Federal-gov', 'Local-gov', 'Never-worked',\n       'Private', 'Self-emp-inc','Self-emp-not-inc', 'State-gov', 'Without-pay', '10th', '11th',\n       '12th', '1st-4th', '5th-6th', '7th-8th', '9th', 'Assoc-acdm',\n       'Assoc-voc', 'Bachelors', 'Doctorate', 'HS-grad', 'Masters',\n       'Preschool', 'Prof-school', 'Some-college', 'Adm-clerical',\n       'Armed-Forces', 'Craft-repair', 'Exec-managerial', 'Farming-fishing',\n       'Handlers-cleaners', 'Machine-op-inspct', 'Other-service',\n       'Priv-house-serv', 'Prof-specialty', 'Protective-serv', 'Sales',\n       'Tech-support', 'Transport-moving', 'Husband', 'Not-in-family',\n       'Other-relative', 'Own-child', 'Unmarried', 'Wife',\n       'Amer-Indian-Eskimo','Asian-Pac-Islander', 'Black', 'Other', 'White', 'Cambodia',\n       'Canada', 'China', 'Columbia', 'Cuba', 'Dominican-Republic', 'Ecuador',\n       'El-Salvador', 'England', 'France', 'Germany', 'Greece', 'Guatemala',\n       'Haiti', 'Holand-Netherlands', 'Honduras', 'Hong', 'Hungary', 'India',\n       'Iran', 'Ireland', 'Italy', 'Jamaica', 'Japan', 'Laos', 'Mexico',\n       'Nicaragua', 'Outlying-US(Guam-USVI-etc)', 'Peru', 'Philippines',\n       'Poland', 'Portugal', 'Puerto-Rico', 'Scotland', 'South', 'Taiwan',\n       'Thailand', 'Trinadad&Tobago', 'United-States', 'Vietnam',\n       'Yugoslavia']]\n\nad = ADASYN()\nX_adasyn,y_adasyn = ad.fit_sample(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"make_model(X_adasyn,y_adasyn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_graphic(X_adasyn,y_adasyn)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6.Conclusions"},{"metadata":{"trusted":true},"cell_type":"code","source":"result = pd.DataFrame(columns = [\"Models\",\"Train f1 Score\",\"Test f1 Score\"])\nresult[\"Models\"]              = [\"Model 1\",\"Model 2\",\"Oversampling\",\"Undersampling\",\"Model Smote\",\"Model Adasyn\"]\nresult[\"Train f1 Score\"]      = [0.0,0.6369504535938589, 0.8191137970688263,0.8098272552783109,\n                                 0.88746921182266,0.8692412954234453]\nresult[\"Test f1 Score\"]       = [0.0,0.6122153957354536,0.8202595390276971,0.823673719717878,\n                                 0.881661041219188,0.8633108039947545]\nresult[\"Accuracy values\"]     = [0.7640104406571473,0.8352525717795178,0.8122977346278317,0.8167038571883966,\n                                 0.8829894822006472,0.8629790676509252]\nresult[\"AUC Values\"]          = [0.5008798249816425,0.8876067714489535,0.887471722122726,0.8921330123827734,\n                                 0.9574314032372933,0.9437558082270674]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = pd.DataFrame(columns = [\"Models\",\"Train f1 Score\",\"Test f1 Score\"])\nresult[\"Models\"]              = [\"Model 1\",\"Model 2\",\"Oversampling\",\"Undersampling\",\"Model Smote\",\"Model Adasyn\"]\nresult[\"Train f1 Score\"]      = [0.0,0.6369504535938589, 0.8191137970688263,0.8098272552783109,\n                                 0.88746921182266,0.8692412954234453]\nresult[\"Test f1 Score\"]       = [0.0,0.6122153957354536,0.8202595390276971,0.823673719717878,\n                                 0.881661041219188,0.8633108039947545]\n\nplt.figure(figsize = (12,8))\n\nn_groups = 6\nindex = np.arange(n_groups)\nbar_width = 0.3\nopacity = 0.7\n \nrects1 = plt.bar(index,result[\"Train f1 Score\"], bar_width,\nalpha=opacity,\ncolor='bisque',\nlabel='Train F1 Score')\n \nrects2 = plt.bar(index + bar_width,result[\"Test f1 Score\"] , bar_width,\nalpha=opacity,\ncolor='navy',\nlabel='Test F1 Score')\n \nplt.xlabel('Models',color=\"navy\",fontsize =17)\nplt.ylabel('F1 Score Values',color=\"navy\",fontsize =17)\nplt.title('Train and Test F1 Score',color=\"navy\",fontsize =18)\nplt.xticks(index + bar_width/2, (\"Model 1\",\"Model 2\",\"Oversampling\",\"Undersampling\",\"Model Smote\",\"Model Adasyn\"),\n           rotation=90,fontsize=12)\nplt.yticks(fontsize=12)\nplt.legend(fontsize='large')\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We prefer models's f1 score values instead of accuracy values because data set is not balanced.\nWhen sorting the models,we pay attention that the overfitting is low and the test f1 score is high.if we sort it \naccording to this,we get the following ranking:\n\n1.Model Smote\n\n2.Model Adasyn\n\n3.Undersampling\n\n4.Oversampling\n\n5.Model2\n\n6.Model1\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":1}