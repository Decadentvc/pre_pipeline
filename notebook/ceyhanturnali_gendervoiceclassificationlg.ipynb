{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"voices=pd.read_csv(\"../input/voicegender/voice.csv\")\nvoices.head()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n\n          kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n0   274.402906  0.893369  0.491918  ...  0.059781  0.084279  0.015702   \n1   634.613855  0.892193  0.513724  ...  0.066009  0.107937  0.015826   \n2  1024.927705  0.846389  0.478905  ...  0.077316  0.098706  0.015656   \n3     4.177296  0.963322  0.727232  ...  0.151228  0.088965  0.017798   \n4     4.333713  0.971955  0.783568  ...  0.135120  0.106398  0.016931   \n\n     maxfun   meandom    mindom    maxdom   dfrange   modindx  label  \n0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000   male  \n1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632   male  \n2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512   male  \n3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119   male  \n4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274   male  \n\n[5 rows x 21 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>meanfreq</th>\n      <th>sd</th>\n      <th>median</th>\n      <th>Q25</th>\n      <th>Q75</th>\n      <th>IQR</th>\n      <th>skew</th>\n      <th>kurt</th>\n      <th>sp.ent</th>\n      <th>sfm</th>\n      <th>...</th>\n      <th>centroid</th>\n      <th>meanfun</th>\n      <th>minfun</th>\n      <th>maxfun</th>\n      <th>meandom</th>\n      <th>mindom</th>\n      <th>maxdom</th>\n      <th>dfrange</th>\n      <th>modindx</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.059781</td>\n      <td>0.064241</td>\n      <td>0.032027</td>\n      <td>0.015071</td>\n      <td>0.090193</td>\n      <td>0.075122</td>\n      <td>12.863462</td>\n      <td>274.402906</td>\n      <td>0.893369</td>\n      <td>0.491918</td>\n      <td>...</td>\n      <td>0.059781</td>\n      <td>0.084279</td>\n      <td>0.015702</td>\n      <td>0.275862</td>\n      <td>0.007812</td>\n      <td>0.007812</td>\n      <td>0.007812</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>male</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.066009</td>\n      <td>0.067310</td>\n      <td>0.040229</td>\n      <td>0.019414</td>\n      <td>0.092666</td>\n      <td>0.073252</td>\n      <td>22.423285</td>\n      <td>634.613855</td>\n      <td>0.892193</td>\n      <td>0.513724</td>\n      <td>...</td>\n      <td>0.066009</td>\n      <td>0.107937</td>\n      <td>0.015826</td>\n      <td>0.250000</td>\n      <td>0.009014</td>\n      <td>0.007812</td>\n      <td>0.054688</td>\n      <td>0.046875</td>\n      <td>0.052632</td>\n      <td>male</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.077316</td>\n      <td>0.083829</td>\n      <td>0.036718</td>\n      <td>0.008701</td>\n      <td>0.131908</td>\n      <td>0.123207</td>\n      <td>30.757155</td>\n      <td>1024.927705</td>\n      <td>0.846389</td>\n      <td>0.478905</td>\n      <td>...</td>\n      <td>0.077316</td>\n      <td>0.098706</td>\n      <td>0.015656</td>\n      <td>0.271186</td>\n      <td>0.007990</td>\n      <td>0.007812</td>\n      <td>0.015625</td>\n      <td>0.007812</td>\n      <td>0.046512</td>\n      <td>male</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.151228</td>\n      <td>0.072111</td>\n      <td>0.158011</td>\n      <td>0.096582</td>\n      <td>0.207955</td>\n      <td>0.111374</td>\n      <td>1.232831</td>\n      <td>4.177296</td>\n      <td>0.963322</td>\n      <td>0.727232</td>\n      <td>...</td>\n      <td>0.151228</td>\n      <td>0.088965</td>\n      <td>0.017798</td>\n      <td>0.250000</td>\n      <td>0.201497</td>\n      <td>0.007812</td>\n      <td>0.562500</td>\n      <td>0.554688</td>\n      <td>0.247119</td>\n      <td>male</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.135120</td>\n      <td>0.079146</td>\n      <td>0.124656</td>\n      <td>0.078720</td>\n      <td>0.206045</td>\n      <td>0.127325</td>\n      <td>1.101174</td>\n      <td>4.333713</td>\n      <td>0.971955</td>\n      <td>0.783568</td>\n      <td>...</td>\n      <td>0.135120</td>\n      <td>0.106398</td>\n      <td>0.016931</td>\n      <td>0.266667</td>\n      <td>0.712812</td>\n      <td>0.007812</td>\n      <td>5.484375</td>\n      <td>5.476562</td>\n      <td>0.208274</td>\n      <td>male</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 21 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"voices.info()","execution_count":3,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3168 entries, 0 to 3167\nData columns (total 21 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   meanfreq  3168 non-null   float64\n 1   sd        3168 non-null   float64\n 2   median    3168 non-null   float64\n 3   Q25       3168 non-null   float64\n 4   Q75       3168 non-null   float64\n 5   IQR       3168 non-null   float64\n 6   skew      3168 non-null   float64\n 7   kurt      3168 non-null   float64\n 8   sp.ent    3168 non-null   float64\n 9   sfm       3168 non-null   float64\n 10  mode      3168 non-null   float64\n 11  centroid  3168 non-null   float64\n 12  meanfun   3168 non-null   float64\n 13  minfun    3168 non-null   float64\n 14  maxfun    3168 non-null   float64\n 15  meandom   3168 non-null   float64\n 16  mindom    3168 non-null   float64\n 17  maxdom    3168 non-null   float64\n 18  dfrange   3168 non-null   float64\n 19  modindx   3168 non-null   float64\n 20  label     3168 non-null   object \ndtypes: float64(20), object(1)\nmemory usage: 519.9+ KB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=voices[['label']].values\ny[0:5]","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"array([['male'],\n       ['male'],\n       ['male'],\n       ['male'],\n       ['male']], dtype=object)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nlabel = preprocessing.LabelEncoder()\nlabel.fit(['male','female'])\ny = label.transform(y) ","execution_count":5,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  return f(**kwargs)\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y[0:5]","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"array([1, 1, 1, 1, 1])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=voices.drop(['label'],axis=1)\nx[0:5]","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n\n          kurt    sp.ent       sfm      mode  centroid   meanfun    minfun  \\\n0   274.402906  0.893369  0.491918  0.000000  0.059781  0.084279  0.015702   \n1   634.613855  0.892193  0.513724  0.000000  0.066009  0.107937  0.015826   \n2  1024.927705  0.846389  0.478905  0.000000  0.077316  0.098706  0.015656   \n3     4.177296  0.963322  0.727232  0.083878  0.151228  0.088965  0.017798   \n4     4.333713  0.971955  0.783568  0.104261  0.135120  0.106398  0.016931   \n\n     maxfun   meandom    mindom    maxdom   dfrange   modindx  \n0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000  \n1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632  \n2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512  \n3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119  \n4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>meanfreq</th>\n      <th>sd</th>\n      <th>median</th>\n      <th>Q25</th>\n      <th>Q75</th>\n      <th>IQR</th>\n      <th>skew</th>\n      <th>kurt</th>\n      <th>sp.ent</th>\n      <th>sfm</th>\n      <th>mode</th>\n      <th>centroid</th>\n      <th>meanfun</th>\n      <th>minfun</th>\n      <th>maxfun</th>\n      <th>meandom</th>\n      <th>mindom</th>\n      <th>maxdom</th>\n      <th>dfrange</th>\n      <th>modindx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.059781</td>\n      <td>0.064241</td>\n      <td>0.032027</td>\n      <td>0.015071</td>\n      <td>0.090193</td>\n      <td>0.075122</td>\n      <td>12.863462</td>\n      <td>274.402906</td>\n      <td>0.893369</td>\n      <td>0.491918</td>\n      <td>0.000000</td>\n      <td>0.059781</td>\n      <td>0.084279</td>\n      <td>0.015702</td>\n      <td>0.275862</td>\n      <td>0.007812</td>\n      <td>0.007812</td>\n      <td>0.007812</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.066009</td>\n      <td>0.067310</td>\n      <td>0.040229</td>\n      <td>0.019414</td>\n      <td>0.092666</td>\n      <td>0.073252</td>\n      <td>22.423285</td>\n      <td>634.613855</td>\n      <td>0.892193</td>\n      <td>0.513724</td>\n      <td>0.000000</td>\n      <td>0.066009</td>\n      <td>0.107937</td>\n      <td>0.015826</td>\n      <td>0.250000</td>\n      <td>0.009014</td>\n      <td>0.007812</td>\n      <td>0.054688</td>\n      <td>0.046875</td>\n      <td>0.052632</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.077316</td>\n      <td>0.083829</td>\n      <td>0.036718</td>\n      <td>0.008701</td>\n      <td>0.131908</td>\n      <td>0.123207</td>\n      <td>30.757155</td>\n      <td>1024.927705</td>\n      <td>0.846389</td>\n      <td>0.478905</td>\n      <td>0.000000</td>\n      <td>0.077316</td>\n      <td>0.098706</td>\n      <td>0.015656</td>\n      <td>0.271186</td>\n      <td>0.007990</td>\n      <td>0.007812</td>\n      <td>0.015625</td>\n      <td>0.007812</td>\n      <td>0.046512</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.151228</td>\n      <td>0.072111</td>\n      <td>0.158011</td>\n      <td>0.096582</td>\n      <td>0.207955</td>\n      <td>0.111374</td>\n      <td>1.232831</td>\n      <td>4.177296</td>\n      <td>0.963322</td>\n      <td>0.727232</td>\n      <td>0.083878</td>\n      <td>0.151228</td>\n      <td>0.088965</td>\n      <td>0.017798</td>\n      <td>0.250000</td>\n      <td>0.201497</td>\n      <td>0.007812</td>\n      <td>0.562500</td>\n      <td>0.554688</td>\n      <td>0.247119</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.135120</td>\n      <td>0.079146</td>\n      <td>0.124656</td>\n      <td>0.078720</td>\n      <td>0.206045</td>\n      <td>0.127325</td>\n      <td>1.101174</td>\n      <td>4.333713</td>\n      <td>0.971955</td>\n      <td>0.783568</td>\n      <td>0.104261</td>\n      <td>0.135120</td>\n      <td>0.106398</td>\n      <td>0.016931</td>\n      <td>0.266667</td>\n      <td>0.712812</td>\n      <td>0.007812</td>\n      <td>5.484375</td>\n      <td>5.476562</td>\n      <td>0.208274</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=preprocessing.StandardScaler().fit(x).transform(x)\nx[0:5]","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"array([[-4.04924806,  0.4273553 , -4.22490077, -2.57610164, -5.69360723,\n        -0.21477826,  2.29330585,  1.76294635, -0.03908279,  0.4715753 ,\n        -2.14121031, -4.04924806, -1.81203825, -1.0979981 ,  0.56595854,\n        -1.5642046 , -0.70840431, -1.43142165, -1.41913712, -1.45477229],\n       [-3.84105325,  0.6116695 , -3.99929342, -2.48688452, -5.58898726,\n        -0.25848536,  4.54805598,  4.43300778, -0.06523603,  0.59443122,\n        -2.14121031, -3.84105325, -1.07959443, -1.09153262, -0.29403034,\n        -1.56191576, -0.70840431, -1.41810716, -1.4058184 , -1.01410294],\n       [-3.46306647,  1.60384791, -4.09585052, -2.7069865 , -3.92869875,\n         0.90932569,  6.51365636,  7.32620677, -1.08373029,  0.39826097,\n        -2.14121031, -3.46306647, -1.36536788, -1.10039656,  0.41048032,\n        -1.56386648, -0.70840431, -1.42920257, -1.41691733, -1.06534356],\n       [-0.99215739,  0.89999793, -0.75945371, -0.90141834, -0.7112046 ,\n         0.63269035, -0.44985837, -0.24009931,  1.51638269,  1.79733981,\n        -1.05457622, -0.99215739, -1.66696584, -0.98893356, -0.29403034,\n        -1.1953668 , -0.70840431, -1.27386686, -1.26153232,  0.61428596],\n       [-1.53064039,  1.32256096, -1.67694793, -1.26839521, -0.79202875,\n         1.0055881 , -0.48091073, -0.23893987,  1.70833622,  2.11473955,\n        -0.79051354, -1.53064039, -1.12723346, -1.03401549,  0.26018471,\n        -0.22165979, -0.70840431,  0.12415445,  0.13693282,  0.28904621]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test=train_test_split(x,y,test_size=0.3,random_state=4)\nprint ('Train set:', X_train.shape,  Y_train.shape)\nprint ('Test set:', X_test.shape,  Y_test.shape)","execution_count":9,"outputs":[{"output_type":"stream","text":"Train set: (2217, 20) (2217,)\nTest set: (951, 20) (951,)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nLR=LogisticRegression(C=0.01,solver='liblinear').fit(X_train,Y_train)\nLR","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"LogisticRegression(C=0.01, solver='liblinear')"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_hat=LR.predict(X_test)\nY_hat","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"array([0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n       0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n       0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n       1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n       0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n       1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n       1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n       1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n       1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n       0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n       1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n       0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n       1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n       0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n       0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n       1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n       1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n       0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n       1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n       1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n       1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n       0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n       0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n       1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n       1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n       1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n       1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1,\n       0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n       1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n       1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n       0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n       1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n       0, 1, 0, 1, 1])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,classification_report\ncnf_matrix = confusion_matrix(Y_test, Y_hat, labels=[1,0])\nnp.set_printoptions(precision=2)\nprint(classification_report(Y_test,Y_hat))","execution_count":14,"outputs":[{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0       0.97      0.95      0.96       468\n           1       0.96      0.98      0.97       483\n\n    accuracy                           0.96       951\n   macro avg       0.96      0.96      0.96       951\nweighted avg       0.96      0.96      0.96       951\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import log_loss\nY_hat_prob=LR.predict_proba(X_test)\nlog_loss(Y_test,Y_hat_prob)","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"0.19087055556086466"},"metadata":{}}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}