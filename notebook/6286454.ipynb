{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Adult income dataset"},{"metadata":{},"cell_type":"markdown","source":"## Step 1. What is the goal of this analysis ?\nThe goal is to train a binary classifier on the training dataset to predict the column income_bracket which has two possible values \">50K\" and \"<=50K\" and evaluate the accuracy of the classifier with the test dataset. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# default libraries\nimport numpy as np\nimport pandas as pd\n\n# for data preprocessing\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\n\n# for classifier models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import KFold, cross_val_score\nimport xgboost as xgb\n\n# for models evaluation\nfrom sklearn.metrics import confusion_matrix, accuracy_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 2. Loading the dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dataset = pd.read_csv(\"/kaggle/input/adult-income-dataset/adult.csv\")\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 3. Exploratory data analysis EDA - Data cleaning and exploration"},{"metadata":{},"cell_type":"markdown","source":"### a. Cleaning the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['income'] = dataset['income'].map({'<=50K':0, '>50K':1})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### b. Making code modular "},{"metadata":{"trusted":true},"cell_type":"code","source":"def init_check(df):\n    \"\"\"\n    A function to make initial check for the dataset including the name, data type, \n    number of null values and number of unique varialbes for each feature.\n    \n    Parameter: dataset(DataFrame)\n    Output : DataFrame\n    \"\"\"\n    columns = df.columns    \n    lst = []\n    for feature in columns : \n        dtype = df[feature].dtypes\n        num_null = df[feature].isnull().sum()\n        num_unique = df[feature].nunique()\n        lst.append([feature, dtype, num_null, num_unique])\n    \n    check_df = pd.DataFrame(lst)\n    check_df.columns = ['feature','dtype','num_null','num_unique']\n    check_df = check_df.sort_values(by='dtype', axis=0, ascending=True)\n    \n    return check_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#init_check?","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"init_check(df=dataset)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### c. Visualizing the data\n\nSkip"},{"metadata":{},"cell_type":"markdown","source":"### d. Feature engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"def categorical_encoding(df, categorical_cloumns, encoding_method):\n    \"\"\"\n    A function to encode categorical features to a one-hot numeric array (one-hot encoding) or \n    an array with value between 0 and n_classes-1 (label encoding).\n    \n    Parameters:\n        df (pd.DataFrame) : dataset\n        categorical_cloumns  (string) : list of features \n        encoding_method (string) : 'one-hot' or 'label'\n    Output : pd.DataFrame\n    \"\"\"\n    \n    if encoding_method == 'label':\n        print('You choose label encoding for your categorical features')\n        encoder = LabelEncoder()\n        encoded = df[categorical_cloumns].apply(encoder.fit_transform)\n        return encoded\n    \n    elif encoding_method == 'one-hot':\n        print('You choose one-hot encoding for your categorical features') \n        encoded = pd.DataFrame()\n        for feature in categorical_cloumns:\n            dummies = pd.get_dummies(df[feature], prefix=feature)\n            encoded = pd.concat([encoded, dummies], axis=1)\n        return encoded","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#categorical_encoding?","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_encoding(df=dataset, categorical_cloumns=['workclass','education'], encoding_method='one-hot')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_encoding(dataset, categorical_cloumns=['workclass','education'], encoding_method='label')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"======================================================================================================="},{"metadata":{"trusted":true},"cell_type":"code","source":"y = dataset['income']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dataset.drop(columns='income', axis=1)\ncategorical_columns = X.select_dtypes(include=['object']).columns\nprint(categorical_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded = categorical_encoding(X, categorical_cloumns=categorical_columns, encoding_method='one-hot')\nencoded.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = X.drop(columns=categorical_columns, axis=1)\nX = pd.concat([X, encoded], axis=1)\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### e. Data split and data scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=123)\n\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler=MinMaxScaler()\nX_train= pd.DataFrame(scaler.fit_transform(X_train))\nX_test = pd.DataFrame(scaler.transform(X_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_preprocessing(df, features, target, encoding_method, test_size, random_state):\n    y = df[target]\n    \n    X = df[features]\n    \n    categorical_columns = X.select_dtypes(include=['object']).columns\n    \n    if len(categorical_columns) != 0 :\n        encoded = categorical_encoding(X, categorical_cloumns=categorical_columns, encoding_method=encoding_method)\n        X = X.drop(columns=categorical_columns, axis=1)\n        X = pd.concat([X, encoded], axis=1)\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n    \n    scaler=MinMaxScaler()\n    X_train= pd.DataFrame(scaler.fit_transform(X_train))\n    X_test = pd.DataFrame(scaler.transform(X_test))\n    \n    return X_train, X_test, y_train, y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = dataset.columns.drop('income')\n\nX_train, X_test, y_train, y_test = data_preprocessing(df=dataset, features=features, \n                                                      target='income', encoding_method = 'label',\n                                                      test_size=0.2, random_state=123)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 4. Data modelling"},{"metadata":{},"cell_type":"markdown","source":"### a. Model performance comparison"},{"metadata":{"trusted":true},"cell_type":"code","source":"def classifiers_estimator(models, scoring, X_train, y_train, k_fold, shuffle, random_state):\n    \"\"\"\n    A function to estimate the performance of each classification model.\n    \n    Parameters:\n        models (string) : list of classificaton models\n        scoring (string) : quantifying the quality of predictions \n        X_train (np.array or pd.dataframe) : features variable of training data\n        y_train (np.array or pd.dataframe) : target of training data\n        k_fold (int) : number of folds\n        shuffle (boolean) : whether to shuffle the data before splitting into batches\n        random_state (int) : it is the seed used by the random number generator\n    \n    Output (pd.DataFrame) : model performance\n    \"\"\"\n    kf = KFold(n_splits=k_fold, shuffle=shuffle, random_state=random_state)\n    \n    results = []\n    for model in models:\n\n        if model == 'RF':\n            estimator = RandomForestClassifier()\n        elif model == 'LR':\n            estimator = RandomForestClassifier()\n        elif model == 'KNN':\n            estimator == KNeighborsClassifier(n_neighbors = 5)\n        elif model == 'XGB':\n            estimator == xgb.XGBClassifier()\n            \n        cv_results = cross_val_score(estimator=estimator, X=X_train, y=y_train, cv=kf, scoring=scoring, n_jobs=-1)\n        cv_mean_accuracy = cv_results.mean()\n        cv_std_accuracy = cv_results.std()\n        cv_max = cv_results.max()\n        cv_min = cv_results.min()\n        results.append([model, cv_mean_accuracy, cv_std_accuracy, cv_max, cv_min])\n        print('Finish %s model' %model)\n    \n    results_df = pd.DataFrame(results)\n    results_df.columns = ['Models','Mean','Std','Max','Min']\n    \n    return results_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#classifiers_estimator?","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### [Model evaluation: quantifying the quality of predictions](https://scikit-learn.org/stable/modules/model_evaluation.html)"},{"metadata":{"trusted":true},"cell_type":"code","source":"classifiers_estimator(['LR', 'RF', 'XGB'], 'accuracy', X_train, y_train, k_fold=6, shuffle=True, random_state=123)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier()\nrf.fit(X_train, y_train)\nprint(rf.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### b. Feature importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"import eli5\nfrom eli5.sklearn import PermutationImportance\n\n# Make a small change to the code below to use in this problem. \nperm = PermutationImportance(rf, random_state=123).fit(X_test, y_test)\n\n# uncomment the following line to visualize your results\neli5.show_weights(perm, feature_names = features.tolist(), top=150)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 5. Loop (Feature selection)"},{"metadata":{"trusted":true},"cell_type":"code","source":"features  = ['education','capital-gain']\n\nX_train, X_test, y_train, y_test = data_preprocessing(df=dataset, features=features, \n                                                      target='income', encoding_method = 'label',\n                                                      test_size=0.2, random_state=123)\n\nclassifiers_estimator(['LR', 'RF', 'XGB'], 'accuracy', X_train, y_train, k_fold=10, shuffle=True, random_state=123)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion"},{"metadata":{},"cell_type":"markdown","source":"1. We can speed up the analysis flow and make analysis more readable by modularizing data preprocess and moelliing process.\n2. What is the difference between the one-hot and label encoding on feature importance ?\n3. Data analysis is not a one-and-done process."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}