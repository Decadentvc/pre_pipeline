{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Source: https://www.kaggle.com/dileep070/heart-disease-prediction-using-logistic-regression**\n",
    "# Data's demographic:\n",
    "• Sex: male(2) or female(0) (Nominal)\n",
    "\n",
    "• Age: Age of the patient;(Continuous - Although the recorded ages have been truncated to whole numbers, the concept of age is continuous) \n",
    "\n",
    "Behavioral\n",
    "\n",
    "• Current Smoker: whether or not the patient is a current smoker (Nominal)\n",
    "\n",
    "• Cigs Per Day: the number of cigarettes that the person smoked on average in one day.(can be considered continuous as one can have any number of cigarettes, even half a cigarette.)\n",
    "\n",
    "Medical( history)\n",
    "\n",
    "• BP Meds: whether or not the patient was on blood pressure medication (Nominal)\n",
    "\n",
    "• Prevalent Stroke: whether or not the patient had previously had a stroke (Nominal)\n",
    "\n",
    "• Prevalent Hyp: whether or not the patient was hypertensive (Nominal)\n",
    "\n",
    "• Diabetes: whether or not the patient had diabetes (Nominal)\n",
    "\n",
    "Medical(current)\n",
    "\n",
    "• Tot Chol: total cholesterol level (Continuous)\n",
    "\n",
    "• Sys BP: systolic blood pressure (Continuous)\n",
    "\n",
    "• Dia BP: diastolic blood pressure (Continuous)\n",
    "\n",
    "• BMI: Body Mass Index (Continuous)\n",
    "\n",
    "• Heart Rate: heart rate (Continuous - In medical research, variables such as heart rate though in fact discrete, yet are considered continuous because of large number of possible values.)\n",
    "\n",
    "• Glucose: glucose level (Continuous)\n",
    "Predict variable (desired target)\n",
    "\n",
    "• 10 year risk of coronary heart disease CHD (binary: “1”, means “Yes”, “0” means “No”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/heart-disease-prediction-using-logistic-regression/framingham.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4238 entries, 0 to 4237\n",
      "Data columns (total 16 columns):\n",
      "male               4238 non-null int64\n",
      "age                4238 non-null int64\n",
      "education          4133 non-null float64\n",
      "currentSmoker      4238 non-null int64\n",
      "cigsPerDay         4209 non-null float64\n",
      "BPMeds             4185 non-null float64\n",
      "prevalentStroke    4238 non-null int64\n",
      "prevalentHyp       4238 non-null int64\n",
      "diabetes           4238 non-null int64\n",
      "totChol            4188 non-null float64\n",
      "sysBP              4238 non-null float64\n",
      "diaBP              4238 non-null float64\n",
      "BMI                4219 non-null float64\n",
      "heartRate          4237 non-null float64\n",
      "glucose            3850 non-null float64\n",
      "TenYearCHD         4238 non-null int64\n",
      "dtypes: float64(9), int64(7)\n",
      "memory usage: 529.9 KB\n"
     ]
    }
   ],
   "source": [
    "# The classification goal is to predict whether the patient has 10-year risk of future coronary heart disease (CHD).\n",
    "#The dataset provides the patients’ information\n",
    "heartDiseaseData = pd.read_csv(\"/kaggle/input/heart-disease-prediction-using-logistic-regression/framingham.csv\")\n",
    "heartDiseaseData.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see my labels are ordered -male = 1, female = 0-. Then i need to delete that useless features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4231</th>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>24.96</td>\n",
       "      <td>80.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4232</th>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>23.14</td>\n",
       "      <td>60.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4233</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>25.97</td>\n",
       "      <td>66.0</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234</th>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>19.71</td>\n",
       "      <td>65.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4237</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>133.5</td>\n",
       "      <td>83.0</td>\n",
       "      <td>21.47</td>\n",
       "      <td>80.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3656 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      male  age  education  currentSmoker  cigsPerDay  BPMeds  \\\n",
       "0        1   39        4.0              0         0.0     0.0   \n",
       "1        0   46        2.0              0         0.0     0.0   \n",
       "2        1   48        1.0              1        20.0     0.0   \n",
       "3        0   61        3.0              1        30.0     0.0   \n",
       "4        0   46        3.0              1        23.0     0.0   \n",
       "...    ...  ...        ...            ...         ...     ...   \n",
       "4231     1   58        3.0              0         0.0     0.0   \n",
       "4232     1   68        1.0              0         0.0     0.0   \n",
       "4233     1   50        1.0              1         1.0     0.0   \n",
       "4234     1   51        3.0              1        43.0     0.0   \n",
       "4237     0   52        2.0              0         0.0     0.0   \n",
       "\n",
       "      prevalentStroke  prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  \\\n",
       "0                   0             0         0    195.0  106.0   70.0  26.97   \n",
       "1                   0             0         0    250.0  121.0   81.0  28.73   \n",
       "2                   0             0         0    245.0  127.5   80.0  25.34   \n",
       "3                   0             1         0    225.0  150.0   95.0  28.58   \n",
       "4                   0             0         0    285.0  130.0   84.0  23.10   \n",
       "...               ...           ...       ...      ...    ...    ...    ...   \n",
       "4231                0             1         0    187.0  141.0   81.0  24.96   \n",
       "4232                0             1         0    176.0  168.0   97.0  23.14   \n",
       "4233                0             1         0    313.0  179.0   92.0  25.97   \n",
       "4234                0             0         0    207.0  126.5   80.0  19.71   \n",
       "4237                0             0         0    269.0  133.5   83.0  21.47   \n",
       "\n",
       "      heartRate  glucose  \n",
       "0          80.0     77.0  \n",
       "1          95.0     76.0  \n",
       "2          75.0     70.0  \n",
       "3          65.0    103.0  \n",
       "4          85.0     85.0  \n",
       "...         ...      ...  \n",
       "4231       80.0     81.0  \n",
       "4232       60.0     79.0  \n",
       "4233       66.0     86.0  \n",
       "4234       65.0     68.0  \n",
       "4237       80.0    107.0  \n",
       "\n",
       "[3656 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#heartDiseaseData.drop([\"education\"], axis = 1, inplace = True) # Delete useless feature.\n",
    "heartDiseaseData.dropna(how=\"any\", inplace = True)  # Delete useless raw\n",
    "\n",
    "chd = heartDiseaseData.TenYearCHD.values \n",
    "featurees = heartDiseaseData.drop([\"TenYearCHD\"], axis = 1) # features before normalization\n",
    "featurees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **NORMALIZATION**\n",
    "\n",
    "Formula = (x -min(x))/(max(x)-min(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.168378</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.232804</td>\n",
       "      <td>0.277024</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.104520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.281314</td>\n",
       "      <td>0.177305</td>\n",
       "      <td>0.349206</td>\n",
       "      <td>0.319680</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.101695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.271047</td>\n",
       "      <td>0.208038</td>\n",
       "      <td>0.338624</td>\n",
       "      <td>0.237518</td>\n",
       "      <td>0.313131</td>\n",
       "      <td>0.084746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.229979</td>\n",
       "      <td>0.314421</td>\n",
       "      <td>0.497354</td>\n",
       "      <td>0.316045</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.177966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.328571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353183</td>\n",
       "      <td>0.219858</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.183228</td>\n",
       "      <td>0.414141</td>\n",
       "      <td>0.127119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4231</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.151951</td>\n",
       "      <td>0.271868</td>\n",
       "      <td>0.349206</td>\n",
       "      <td>0.228308</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.115819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4232</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129363</td>\n",
       "      <td>0.399527</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.184198</td>\n",
       "      <td>0.161616</td>\n",
       "      <td>0.110169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4233</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.410678</td>\n",
       "      <td>0.451537</td>\n",
       "      <td>0.465608</td>\n",
       "      <td>0.252787</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.129944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.193018</td>\n",
       "      <td>0.203310</td>\n",
       "      <td>0.338624</td>\n",
       "      <td>0.101066</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.079096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4237</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.320329</td>\n",
       "      <td>0.236407</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.143723</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.189266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3656 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      male       age  education  currentSmoker  cigsPerDay  BPMeds  \\\n",
       "0      1.0  0.184211   1.000000            0.0    0.000000     0.0   \n",
       "1      0.0  0.368421   0.333333            0.0    0.000000     0.0   \n",
       "2      1.0  0.421053   0.000000            1.0    0.285714     0.0   \n",
       "3      0.0  0.763158   0.666667            1.0    0.428571     0.0   \n",
       "4      0.0  0.368421   0.666667            1.0    0.328571     0.0   \n",
       "...    ...       ...        ...            ...         ...     ...   \n",
       "4231   1.0  0.684211   0.666667            0.0    0.000000     0.0   \n",
       "4232   1.0  0.947368   0.000000            0.0    0.000000     0.0   \n",
       "4233   1.0  0.473684   0.000000            1.0    0.014286     0.0   \n",
       "4234   1.0  0.500000   0.666667            1.0    0.614286     0.0   \n",
       "4237   0.0  0.526316   0.333333            0.0    0.000000     0.0   \n",
       "\n",
       "      prevalentStroke  prevalentHyp  diabetes   totChol     sysBP     diaBP  \\\n",
       "0                 0.0           0.0       0.0  0.168378  0.106383  0.232804   \n",
       "1                 0.0           0.0       0.0  0.281314  0.177305  0.349206   \n",
       "2                 0.0           0.0       0.0  0.271047  0.208038  0.338624   \n",
       "3                 0.0           1.0       0.0  0.229979  0.314421  0.497354   \n",
       "4                 0.0           0.0       0.0  0.353183  0.219858  0.380952   \n",
       "...               ...           ...       ...       ...       ...       ...   \n",
       "4231              0.0           1.0       0.0  0.151951  0.271868  0.349206   \n",
       "4232              0.0           1.0       0.0  0.129363  0.399527  0.518519   \n",
       "4233              0.0           1.0       0.0  0.410678  0.451537  0.465608   \n",
       "4234              0.0           0.0       0.0  0.193018  0.203310  0.338624   \n",
       "4237              0.0           0.0       0.0  0.320329  0.236407  0.370370   \n",
       "\n",
       "           BMI  heartRate   glucose  \n",
       "0     0.277024   0.363636  0.104520  \n",
       "1     0.319680   0.515152  0.101695  \n",
       "2     0.237518   0.313131  0.084746  \n",
       "3     0.316045   0.212121  0.177966  \n",
       "4     0.183228   0.414141  0.127119  \n",
       "...        ...        ...       ...  \n",
       "4231  0.228308   0.363636  0.115819  \n",
       "4232  0.184198   0.161616  0.110169  \n",
       "4233  0.252787   0.222222  0.129944  \n",
       "4234  0.101066   0.212121  0.079096  \n",
       "4237  0.143723   0.363636  0.189266  \n",
       "\n",
       "[3656 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = (featurees - np.min(featurees))/(np.max(featurees) - np.min(featurees)).values # features after normalization\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TRAIN-TEST SPLIT**\n",
    "\n",
    "Train Test Split data==> 80% of data set for Train, 20% of data set for Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed of Features and Values place.\n",
      "features_train:  (15, 2924)\n",
      "features_test  (15, 732)\n",
      "chd_train:  (2924,)\n",
      "chd_test:  (732,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "features_train, features_test, chd_train, chd_test = train_test_split(features, chd ,test_size = 0.2 , random_state = 42)\n",
    "# test_size ==> 80% of data set for Train, 20% of data set for Test\n",
    "\n",
    "\n",
    "features_train = features_train.T\n",
    "features_test = features_test.T\n",
    "chd_train = chd_train.T\n",
    "chd_test = chd_test.T\n",
    "\n",
    "print(\"Changed of Features and Values place.\")\n",
    "\n",
    "print(\"features_train: \", features_train.shape)\n",
    "print(\"features_test \", features_test.shape)\n",
    "print(\"chd_train: \", chd_train.shape)\n",
    "print(\"chd_test: \", chd_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PARAMETER INITALIZE AND SIGMOID FUNCTION**\n",
    "\n",
    "Time to start defining functions.First of all I need to initialize my weights and bias, then I will need a sigmoid function.\n",
    "\n",
    "Sigmoid Function : f(x) = 1 / ( 1 + (e ^ -x)\n",
    "Initialize weight = 0.01 for each data\n",
    "Initialize bias = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights_and_bias(dimension):\n",
    "    \n",
    "    weights = np.full((dimension,1), 0.01) \n",
    "    bias = 0.0 \n",
    "    return weights,bias\n",
    "    \n",
    "def sigmoid(z):\n",
    "    chd_head = 1/(1+np.exp(-z))\n",
    "    return chd_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **FORWARD AND BACKWARD PROPAGATION FUNCTION**\n",
    "z = bias + px1w1 + px2w2 + ... + pxn*wn\n",
    "loss function = -(1 - y) log(1- y_head) - y log(y_head)\n",
    "cost function = sum(loss value) / train dataset sample count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_backward_propagation(weights, bias , features_train, chd_train):\n",
    "    #forward propagation\n",
    "    \n",
    "    z = np.dot(weights.T,features_train) + bias\n",
    "    chd_head = sigmoid(z)\n",
    "    loss = -chd_train*np.log(chd_head) - (1- chd_train)*np.log(1-chd_head)\n",
    "    cost = (np.sum(loss))/features_train.shape[1]\n",
    "    \n",
    "    #backward propagation\n",
    "    derivative_weights = (np.dot(features_train,((chd_head-chd_train).T)))/features_train.shape[1] \n",
    "    derivative_bias = np.sum(chd_head-chd_train)/features_train.shape[1] \n",
    "    gradients = {\"derivative_weights\" : derivative_weights, \"derivative_bias\" : derivative_bias}\n",
    "    return cost,gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **UPDATE**\n",
    "Update weights and bias with backward-forward propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(weights, bias, features_train, chd_train, learning_rate, number_of_iterations):\n",
    "    cost_list = []\n",
    "    cost_list2 = []\n",
    "    index = []\n",
    "    \n",
    "    for i in range(number_of_iterations):\n",
    "        \n",
    "        cost, gradients = forward_backward_propagation(weights, bias, features_train, chd_train)\n",
    "        cost_list.append(cost)\n",
    "        \n",
    "        weights = weights - learning_rate* gradients[\"derivative_weights\"]\n",
    "        bias = bias - learning_rate*gradients[\"derivative_bias\"]\n",
    "        \n",
    "        if i % 10 == 0: # her 10 adımda bir depolar\n",
    "            cost_list2.append(cost)\n",
    "            index.append(i)\n",
    "            print(\"Cost after iterations %i: %f \" %(i,cost))\n",
    "            \n",
    "        \n",
    "    parameters =  {\"weights\" : weights, \"bias\" : bias}\n",
    "    plt.plot(index,cost_list2)\n",
    "    plt.xticks(index, rotation = \"vertical\")\n",
    "    plt.xlabel(\"Number Of Iterations\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.show()\n",
    "    return parameters, gradients, cost_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PREDICT**\n",
    "Predict function for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(weights, bias, features_test):\n",
    "    \n",
    "    z = sigmoid(np.dot(weights.T,features_test)+bias)\n",
    "    chd_prediction = np.zeros((1,features_test.shape[1]))\n",
    "    \n",
    "    \n",
    "    for i in range(z.shape[1]):\n",
    "        if z[0,i] <= 0.5 :\n",
    "            chd_prediction[0,i] = 0\n",
    "        else:\n",
    "            chd_prediction[0,i] = 1\n",
    "            \n",
    "    return chd_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LOGISTIC REGRESSION**\n",
    "Main part.\n",
    "Put it all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iterations 0: 0.705554 \n",
      "Cost after iterations 10: 0.401080 \n",
      "Cost after iterations 20: 0.389677 \n",
      "Cost after iterations 30: 0.383909 \n",
      "Cost after iterations 40: 0.380201 \n",
      "Cost after iterations 50: 0.377660 \n",
      "Cost after iterations 60: 0.375852 \n",
      "Cost after iterations 70: 0.374521 \n",
      "Cost after iterations 80: 0.373509 \n",
      "Cost after iterations 90: 0.372717 \n",
      "Cost after iterations 100: 0.372080 \n",
      "Cost after iterations 110: 0.371557 \n",
      "Cost after iterations 120: 0.371118 \n",
      "Cost after iterations 130: 0.370745 \n",
      "Cost after iterations 140: 0.370422 \n",
      "Cost after iterations 150: 0.370141 \n",
      "Cost after iterations 160: 0.369893 \n",
      "Cost after iterations 170: 0.369674 \n",
      "Cost after iterations 180: 0.369477 \n",
      "Cost after iterations 190: 0.369301 \n",
      "Cost after iterations 200: 0.369143 \n",
      "Cost after iterations 210: 0.368999 \n",
      "Cost after iterations 220: 0.368869 \n",
      "Cost after iterations 230: 0.368751 \n",
      "Cost after iterations 240: 0.368642 \n",
      "Cost after iterations 250: 0.368543 \n",
      "Cost after iterations 260: 0.368452 \n",
      "Cost after iterations 270: 0.368369 \n",
      "Cost after iterations 280: 0.368292 \n",
      "Cost after iterations 290: 0.368220 \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test occuracy: 83.7431693989071% \n"
     ]
    }
   ],
   "source": [
    "# def logistic_regression(features_train, chd_train, features_test, chd_test, learning_rate, number_of_iterations):\n",
    "#     dimension = features_train.shape[0] # that is 14(features)\n",
    "#     weights, bias = initialize_weights_and_bias(dimension)\n",
    "    \n",
    "#     parameters, gradients, cost_list = update(weights, bias, features_train, chd_train, learning_rate, number_of_iterations) \n",
    "    \n",
    "#     chd_prediction_test = predict(parameters[\"weights\"], parameters[\"bias\"], features_test)\n",
    "    \n",
    "#     print(\"Test occuracy: {}% \".format(100-np.mean(np.abs(chd_prediction_test - chd_test))*100))\n",
    "    \n",
    "# logistic_regression(features_train, chd_train, features_test, chd_test, learning_rate = 5, number_of_iterations = 300) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Logistic Regression with Sklearn Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.837431693989071\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(features_train.T,chd_train.T)\n",
    "print(\"test accuracy {}\".format(lr.score(features_test.T,chd_test.T)))\n",
    "features_train = features_train.T\n",
    "chd_train = chd_train.T\n",
    "features_test = features_test.T\n",
    "chd_test = chd_test.T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
