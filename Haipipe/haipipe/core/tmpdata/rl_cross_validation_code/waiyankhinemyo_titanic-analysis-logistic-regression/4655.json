{"seq": [{"operator": "ImputerMedian", "edge_id": "15---after"}, {"operator": "ImputerCatMode", "edge_id": "17---after"}, {"operator": "LabelEncoder", "edge_id": "48---after"}, {"operator": "PolynomialFeatures", "edge_id": "48---after"}, {"operator": "MinMaxScaler", "edge_id": "48---after"}], "code": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport math\nimport seaborn as sns\n#sns.set()\nfrom mpl_toolkits.mplot3d import Axes3D\nimport time\nfrom datetime import date\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\ndata = '../input/titanicdataset-traincsv/train.csv'\ndataset = pd.read_csv(data)\ndataset.shape\ndataset.dtypes\ndataset.describe()\ndataset.head(10)\nprint(\"Total number of passengers in the dataset: \" + str(len(dataset.index)))\n#sns.countplot(x=\"Survived\", data=dataset)\n#sns.countplot(x=\"Survived\", hue=\"Sex\", data=dataset)\n#sns.countplot(x=\"Survived\", hue=\"Pclass\", data=dataset)\ndataset[\"Age\"].plot.hist()\n#sns.boxplot(x=\"Survived\", y=\"Age\", data=dataset)\ndataset[\"Pclass\"].plot.hist()\n#sns.boxplot(x=\"Pclass\", y=\"Age\", data=dataset)\ndataset[\"Fare\"].plot.hist(figsize=(10,10))\ndataset.info()\n#sns.countplot(x=\"SibSp\", data=dataset)\n#sns.countplot(x=\"Parch\", data=dataset)\ndataset.isnull()\ndataset.isnull().sum()\n#sns.heatmap(dataset.isnull(), yticklabels=False, cmap=\"viridis\")\ndataset.head()\ndataset.drop(\"Cabin\", axis=1, inplace=True)\ndataset.head()\n#sns.heatmap(dataset.isnull(), yticklabels=False, cmap=\"viridis\")\ndataset.dropna(inplace=True)\n#sns.heatmap(dataset.isnull(), yticklabels=False, cmap=\"viridis\")\ndataset.isnull().sum()\ndataset.shape\ndataset.head()\ndataset.Pclass.unique()\ndataset.Sex.unique()\ndataset.Embarked.unique()\nPcl=pd.get_dummies(dataset[\"Pclass\"],drop_first=True)\nPcl.head()\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nX = dataset\na = dataset['Sex']\nX['Sex'] = le.fit_transform(X['Sex'])\na = le.transform(a)\ndataset = X\nembark=pd.get_dummies(dataset[\"Embarked\"])\nembark.head()\ndataset=pd.concat([dataset,embark,Pcl],axis=1)\ndataset.head()\ndataset.drop(['PassengerId','Pclass', 'Name','Ticket','Embarked'],axis=1, inplace=True)\n\nfrom sklearn.preprocessing import PolynomialFeatures\nimport pandas as pd\nimport numpy as np\n        \ndataset = pd.DataFrame(dataset).reset_index(drop=True).infer_objects()\nadd_engine = PolynomialFeatures(include_bias=False)\nadd_engine.fit(dataset)\ntrain_data_x = add_engine.transform(dataset)\ntrain_data_x = pd.DataFrame(train_data_x)\ndataset = train_data_x.loc[:, ~train_data_x.columns.duplicated()]\n        \n\nfrom sklearn.preprocessing import MinMaxScaler\nimport pandas as pd\nimport numpy as np\ndef catch_num(data):\n    num_cols = [col for col in data.columns if str(data[col].dtypes) != 'object']\n    cat_cols = [col for col in data.columns if col not in num_cols]\n    cat_train_x = data[cat_cols]\n    num_train_x = data[num_cols]\n    return cat_train_x, num_train_x\n        \nadd_scaler = MinMaxScaler()\ndataset = pd.DataFrame(dataset).reset_index(drop=True).infer_objects()\ncat_train_x, num_train_x = catch_num(dataset)\nadd_scaler.fit(num_train_x)\nnum_train_x = pd.DataFrame(add_scaler.transform(num_train_x), columns=list(num_train_x.columns)).reset_index(drop=True).infer_objects()\ndataset = pd.concat([cat_train_x.reset_index(drop=True), num_train_x.reset_index(drop=True)],axis=1)\n        \ndataset.head()\ncorr_mat=dataset.corr()\n#plt.figure(figsize=(13,5))\n#sns_plot=sns.heatmap(data=corr_mat, annot=True, cmap='GnBu')\n#plt.show()\nX = dataset.drop(\"Survived\", axis=1)\ny = dataset[\"Survived\"]\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=1-0.8, random_state=0)\nfrom sklearn.linear_model import LogisticRegression\nlogmodel=LogisticRegression()\n#logmodel.fit(X_train,y_train)\n#predictions = logmodel.predict(X_test)\n#print(predictions)\nfrom sklearn.metrics import classification_report\n#print(classification_report(y_test,predictions))\nfrom sklearn.metrics import confusion_matrix\n#confusion_matrix(y_test, predictions)\nfrom sklearn.metrics import accuracy_score \n#accuracy_score(y_test,predictions) \n\n\n\n\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model.logistic import LogisticRegression\n#print(\"start running model training........\")\nmodel = LogisticRegression(solver='liblinear', random_state=0)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nscore = accuracy_score(y_test, y_pred)\nimport numpy as np\nnp.save(\"haipipe/core/tmpdata/merge_max_result_rl/waiyankhinemyo_titanic-analysis-logistic-regression/4655.npy\", { \"accuracy_score\": score })\n\n\n", "validation_code": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport math\nimport seaborn as sns\n#sns.set()\nfrom mpl_toolkits.mplot3d import Axes3D\nimport time\nfrom datetime import date\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\ndata = '../input/titanicdataset-traincsv/train.csv'\ndataset = pd.read_csv(data)\ndataset.shape\ndataset.dtypes\ndataset.describe()\ndataset.head(10)\nprint(\"Total number of passengers in the dataset: \" + str(len(dataset.index)))\n#sns.countplot(x=\"Survived\", data=dataset)\n#sns.countplot(x=\"Survived\", hue=\"Sex\", data=dataset)\n#sns.countplot(x=\"Survived\", hue=\"Pclass\", data=dataset)\ndataset[\"Age\"].plot.hist()\n#sns.boxplot(x=\"Survived\", y=\"Age\", data=dataset)\ndataset[\"Pclass\"].plot.hist()\n#sns.boxplot(x=\"Pclass\", y=\"Age\", data=dataset)\ndataset[\"Fare\"].plot.hist(figsize=(10,10))\ndataset.info()\n#sns.countplot(x=\"SibSp\", data=dataset)\n#sns.countplot(x=\"Parch\", data=dataset)\ndataset.isnull()\ndataset.isnull().sum()\n#sns.heatmap(dataset.isnull(), yticklabels=False, cmap=\"viridis\")\ndataset.head()\ndataset.drop(\"Cabin\", axis=1, inplace=True)\ndataset.head()\n#sns.heatmap(dataset.isnull(), yticklabels=False, cmap=\"viridis\")\ndataset.dropna(inplace=True)\n#sns.heatmap(dataset.isnull(), yticklabels=False, cmap=\"viridis\")\ndataset.isnull().sum()\ndataset.shape\ndataset.head()\ndataset.Pclass.unique()\ndataset.Sex.unique()\ndataset.Embarked.unique()\nPcl=pd.get_dummies(dataset[\"Pclass\"],drop_first=True)\nPcl.head()\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nX = dataset\na = dataset['Sex']\nX['Sex'] = le.fit_transform(X['Sex'])\na = le.transform(a)\ndataset = X\nembark=pd.get_dummies(dataset[\"Embarked\"])\nembark.head()\ndataset=pd.concat([dataset,embark,Pcl],axis=1)\ndataset.head()\ndataset.drop(['PassengerId','Pclass', 'Name','Ticket','Embarked'],axis=1, inplace=True)\n\nfrom sklearn.preprocessing import PolynomialFeatures\nimport pandas as pd\nimport numpy as np\n        \ndataset = pd.DataFrame(dataset).reset_index(drop=True).infer_objects()\nadd_engine = PolynomialFeatures(include_bias=False)\nadd_engine.fit(dataset)\ntrain_data_x = add_engine.transform(dataset)\ntrain_data_x = pd.DataFrame(train_data_x)\ndataset = train_data_x.loc[:, ~train_data_x.columns.duplicated()]\n        \n\nfrom sklearn.preprocessing import MinMaxScaler\nimport pandas as pd\nimport numpy as np\ndef catch_num(data):\n    num_cols = [col for col in data.columns if str(data[col].dtypes) != 'object']\n    cat_cols = [col for col in data.columns if col not in num_cols]\n    cat_train_x = data[cat_cols]\n    num_train_x = data[num_cols]\n    return cat_train_x, num_train_x\n        \nadd_scaler = MinMaxScaler()\ndataset = pd.DataFrame(dataset).reset_index(drop=True).infer_objects()\ncat_train_x, num_train_x = catch_num(dataset)\nadd_scaler.fit(num_train_x)\nnum_train_x = pd.DataFrame(add_scaler.transform(num_train_x), columns=list(num_train_x.columns)).reset_index(drop=True).infer_objects()\ndataset = pd.concat([cat_train_x.reset_index(drop=True), num_train_x.reset_index(drop=True)],axis=1)\n        \ndataset.head()\ncorr_mat=dataset.corr()\n#plt.figure(figsize=(13,5))\n#sns_plot=sns.heatmap(data=corr_mat, annot=True, cmap='GnBu')\n#plt.show()\nX = dataset.drop(\"Survived\", axis=1)\ny = dataset[\"Survived\"]\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=1-0.8, random_state=0)\nfrom sklearn.linear_model import LogisticRegression\nlogmodel=LogisticRegression()\n#logmodel.fit(X_train,y_train)\n#predictions = logmodel.predict(X_test)\n#print(predictions)\nfrom sklearn.metrics import classification_report\n#print(classification_report(y_test,predictions))\nfrom sklearn.metrics import confusion_matrix\n#confusion_matrix(y_test, predictions)\nfrom sklearn.metrics import accuracy_score \n#accuracy_score(y_test,predictions) \n\n\n\n\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model.logistic import LogisticRegression\n#print(\"start running model training........\")\nmodel = LogisticRegression(solver='liblinear', random_state=0)\n#model.fit(X_train, y_train)\n#y_pred = model.predict(x_validation_varible)\n#score = accuracy_score(y_validation_varible, y_pred)\nfrom sklearn.model_selection import cross_val_score\ncross_score = cross_val_score(model, X_train, y_train,cv=4)\nimport numpy as np\n#np.save(\"haipipe/core/tmpdata/merge_max_result_rl/waiyankhinemyo_titanic-analysis-logistic-regression/4655.npy\", { \"accuracy_score\": score })\nnp.save(\"haipipe/core/tmpdata/rl_cross_val_res/waiyankhinemyo_titanic-analysis-logistic-regression/4655.npy\", { \"accuracy_score\": cross_score })\n\n\n\n"}