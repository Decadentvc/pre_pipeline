{"seq": [{"operator": "MinMaxScaler", "edge_id": "end"}], "code": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\ndataset = pd.read_csv('../input/social-network-ads/Social_Network_Ads.csv')\ndataset.head(n= 10)  \ndataset.isnull().sum()\ndataset.info()\ndataset.describe()\n#sns.countplot(dataset['Purchased'])\n#plt.title('Distribution of Purchased or not')\n#plt.xlabel('Purchased or not')\n#plt.ylabel('Frequency')\n#plt.show()\n#plt.figure(figsize = (10,6))\n#plt.hist(dataset['Age'], bins  = 6, color = 'blue', rwidth = 0.98)\n#plt.title('Distribution of Age')\n#plt.xlabel('Different Ages')\n#plt.ylabel('Frequency')\n#plt.figure(figsize = (10,6))\n#plt.hist(dataset['EstimatedSalary'], bins = 10, color = 'green',rwidth = 0.97)\n#plt.title('Distribution of EstimatedSalaries')\n#plt.xlabel('Different Salaries')\n#plt.ylabel('Frequency')\n#sns.pairplot(dataset, hue = 'Purchased')\n#sns.heatmap(dataset.corr(), annot = True, cmap = \"RdYlGn\")\nX = dataset.iloc[:,[2,3]].values\nprint(X)\ny = dataset.iloc[:,4].values\nprint(y)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=1-0.8, random_state=0)\n\nfrom sklearn.preprocessing import MinMaxScaler\nimport pandas as pd\nimport numpy as np\ndef catch_num(data):\n    num_cols = [col for col in data.columns if str(data[col].dtypes) != 'object']\n    cat_cols = [col for col in data.columns if col not in num_cols]\n    cat_train_x = data[cat_cols]\n    num_train_x = data[num_cols]\n    return cat_train_x, num_train_x\n        \nadd_scaler = MinMaxScaler()\nX = pd.DataFrame(X).reset_index(drop=True).infer_objects()\ncat_train_x, num_train_x = catch_num(X)\nadd_scaler.fit(num_train_x)\nnum_train_x = pd.DataFrame(add_scaler.transform(num_train_x), columns=list(num_train_x.columns)).reset_index(drop=True).infer_objects()\nX = pd.concat([cat_train_x.reset_index(drop=True), num_train_x.reset_index(drop=True)],axis=1)\n        \nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test  = sc.transform(X_test)\nprint(X_train)\nprint(X_test)\nfrom sklearn.neighbors import KNeighborsClassifier\nerror_rate = []\nfor i in range(1,40):\n    knn = KNeighborsClassifier(n_neighbors = i)\n#    knn.fit(X_train, y_train)\n#    score = knn.predict(X_test)\n#    error_rate.append(1-score.mean())\n#plt.figure(figsize =(10,6))\n#plt.plot(range(1,40), error_rate, color = 'blue', linestyle = 'dashed', marker = 'o', markerfacecolor = 'red', markersize = 10)\n#plt.title('Error rate vs K-value')\n#plt.xlabel('K')\n#plt.ylabel('Error Rate')\n#plt.show()\nfrom sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n#classifier.fit(X_train, y_train)\n#y_pred = classifier.predict(X_test)\nfrom sklearn.metrics import confusion_matrix,accuracy_score\n#cm1 = confusion_matrix(y_test,y_pred)\n#print(cm1)   \n#ac1 = accuracy_score(y_test, y_pred)*100\n#print(ac1)\n#plt.figure(figsize = (12,8))\nfrom matplotlib.colors import ListedColormap\nX_set, y_set = X_train, y_train\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n#plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n#plt.xlim(X1.min(), X1.max())\n#plt.ylim(X2.min(), X2.max())\n#for i, j in enumerate(np.unique(y_set)):\n#    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],                color = ListedColormap(('red', 'green'))(i), label = j)\n#plt.title('kNN (Training set)')\n#plt.xlabel('Age')\n#plt.ylabel('Estimated Salary')\n#plt.legend()\n#plt.show()\n#plt.figure(figsize = (12,8))\nfrom matplotlib.colors import ListedColormap\nX_set, y_set = X_test, y_test\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n#plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n#plt.xlim(X1.min(), X1.max())\n#plt.ylim(X2.min(), X2.max())\n#for i, j in enumerate(np.unique(y_set)):\n#    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],                color = ListedColormap(('red', 'green'))(i), label = j)\n#plt.title('kNN (Testing set)')\n#plt.xlabel('Age')\n#plt.ylabel('Estimated Salary')\n#plt.legend()\n#plt.show()\n\n\n\n\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.neighbors import KNeighborsClassifier\n#print(\"start running model training........\")\nmodel = KNeighborsClassifier()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nscore = accuracy_score(y_test, y_pred)\nimport numpy as np\nnp.save(\"haipipe/core/tmpdata/merge_max_result_rl/monukhan_predict-person-purchased-the-product-or-not/5.npy\", { \"accuracy_score\": score })\n\n"}