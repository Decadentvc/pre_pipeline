{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":18,"outputs":[{"output_type":"stream","text":"/kaggle/input/heart-disease-prediction-using-logistic-regression/framingham.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/heart-disease-prediction-using-logistic-regression/framingham.csv')","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":20,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4238 entries, 0 to 4237\nData columns (total 16 columns):\n #   Column           Non-Null Count  Dtype  \n---  ------           --------------  -----  \n 0   male             4238 non-null   int64  \n 1   age              4238 non-null   int64  \n 2   education        4133 non-null   float64\n 3   currentSmoker    4238 non-null   int64  \n 4   cigsPerDay       4209 non-null   float64\n 5   BPMeds           4185 non-null   float64\n 6   prevalentStroke  4238 non-null   int64  \n 7   prevalentHyp     4238 non-null   int64  \n 8   diabetes         4238 non-null   int64  \n 9   totChol          4188 non-null   float64\n 10  sysBP            4238 non-null   float64\n 11  diaBP            4238 non-null   float64\n 12  BMI              4219 non-null   float64\n 13  heartRate        4237 non-null   float64\n 14  glucose          3850 non-null   float64\n 15  TenYearCHD       4238 non-null   int64  \ndtypes: float64(9), int64(7)\nmemory usage: 529.9 KB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe(include='all')","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"              male          age    education  currentSmoker   cigsPerDay  \\\ncount  4238.000000  4238.000000  4133.000000    4238.000000  4209.000000   \nmean      0.429212    49.584946     1.978950       0.494101     9.003089   \nstd       0.495022     8.572160     1.019791       0.500024    11.920094   \nmin       0.000000    32.000000     1.000000       0.000000     0.000000   \n25%       0.000000    42.000000     1.000000       0.000000     0.000000   \n50%       0.000000    49.000000     2.000000       0.000000     0.000000   \n75%       1.000000    56.000000     3.000000       1.000000    20.000000   \nmax       1.000000    70.000000     4.000000       1.000000    70.000000   \n\n            BPMeds  prevalentStroke  prevalentHyp     diabetes      totChol  \\\ncount  4185.000000      4238.000000   4238.000000  4238.000000  4188.000000   \nmean      0.029630         0.005899      0.310524     0.025720   236.721585   \nstd       0.169584         0.076587      0.462763     0.158316    44.590334   \nmin       0.000000         0.000000      0.000000     0.000000   107.000000   \n25%       0.000000         0.000000      0.000000     0.000000   206.000000   \n50%       0.000000         0.000000      0.000000     0.000000   234.000000   \n75%       0.000000         0.000000      1.000000     0.000000   263.000000   \nmax       1.000000         1.000000      1.000000     1.000000   696.000000   \n\n             sysBP        diaBP          BMI    heartRate      glucose  \\\ncount  4238.000000  4238.000000  4219.000000  4237.000000  3850.000000   \nmean    132.352407    82.893464    25.802008    75.878924    81.966753   \nstd      22.038097    11.910850     4.080111    12.026596    23.959998   \nmin      83.500000    48.000000    15.540000    44.000000    40.000000   \n25%     117.000000    75.000000    23.070000    68.000000    71.000000   \n50%     128.000000    82.000000    25.400000    75.000000    78.000000   \n75%     144.000000    89.875000    28.040000    83.000000    87.000000   \nmax     295.000000   142.500000    56.800000   143.000000   394.000000   \n\n        TenYearCHD  \ncount  4238.000000  \nmean      0.151958  \nstd       0.359023  \nmin       0.000000  \n25%       0.000000  \n50%       0.000000  \n75%       0.000000  \nmax       1.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>male</th>\n      <th>age</th>\n      <th>education</th>\n      <th>currentSmoker</th>\n      <th>cigsPerDay</th>\n      <th>BPMeds</th>\n      <th>prevalentStroke</th>\n      <th>prevalentHyp</th>\n      <th>diabetes</th>\n      <th>totChol</th>\n      <th>sysBP</th>\n      <th>diaBP</th>\n      <th>BMI</th>\n      <th>heartRate</th>\n      <th>glucose</th>\n      <th>TenYearCHD</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>4238.000000</td>\n      <td>4238.000000</td>\n      <td>4133.000000</td>\n      <td>4238.000000</td>\n      <td>4209.000000</td>\n      <td>4185.000000</td>\n      <td>4238.000000</td>\n      <td>4238.000000</td>\n      <td>4238.000000</td>\n      <td>4188.000000</td>\n      <td>4238.000000</td>\n      <td>4238.000000</td>\n      <td>4219.000000</td>\n      <td>4237.000000</td>\n      <td>3850.000000</td>\n      <td>4238.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.429212</td>\n      <td>49.584946</td>\n      <td>1.978950</td>\n      <td>0.494101</td>\n      <td>9.003089</td>\n      <td>0.029630</td>\n      <td>0.005899</td>\n      <td>0.310524</td>\n      <td>0.025720</td>\n      <td>236.721585</td>\n      <td>132.352407</td>\n      <td>82.893464</td>\n      <td>25.802008</td>\n      <td>75.878924</td>\n      <td>81.966753</td>\n      <td>0.151958</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.495022</td>\n      <td>8.572160</td>\n      <td>1.019791</td>\n      <td>0.500024</td>\n      <td>11.920094</td>\n      <td>0.169584</td>\n      <td>0.076587</td>\n      <td>0.462763</td>\n      <td>0.158316</td>\n      <td>44.590334</td>\n      <td>22.038097</td>\n      <td>11.910850</td>\n      <td>4.080111</td>\n      <td>12.026596</td>\n      <td>23.959998</td>\n      <td>0.359023</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>32.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>107.000000</td>\n      <td>83.500000</td>\n      <td>48.000000</td>\n      <td>15.540000</td>\n      <td>44.000000</td>\n      <td>40.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>42.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>206.000000</td>\n      <td>117.000000</td>\n      <td>75.000000</td>\n      <td>23.070000</td>\n      <td>68.000000</td>\n      <td>71.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>49.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>234.000000</td>\n      <td>128.000000</td>\n      <td>82.000000</td>\n      <td>25.400000</td>\n      <td>75.000000</td>\n      <td>78.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.000000</td>\n      <td>56.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>20.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>263.000000</td>\n      <td>144.000000</td>\n      <td>89.875000</td>\n      <td>28.040000</td>\n      <td>83.000000</td>\n      <td>87.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>70.000000</td>\n      <td>4.000000</td>\n      <td>1.000000</td>\n      <td>70.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>696.000000</td>\n      <td>295.000000</td>\n      <td>142.500000</td>\n      <td>56.800000</td>\n      <td>143.000000</td>\n      <td>394.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"male                 0\nage                  0\neducation          105\ncurrentSmoker        0\ncigsPerDay          29\nBPMeds              53\nprevalentStroke      0\nprevalentHyp         0\ndiabetes             0\ntotChol             50\nsysBP                0\ndiaBP                0\nBMI                 19\nheartRate            1\nglucose            388\nTenYearCHD           0\ndtype: int64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"We notice that there are nulls in columns. Lets replace them with mean, median and mode of a particular variable.\n\nThe way to input data in NULL Value:\n\nDelete data with complete.cases () if the amount of NULL Value data is not too much\n\nReplace the data with mean () if the data is numeric and there is no outlier\n\nReplace the data with median () if the data is numeric and there is outlier\n\nReplace data with mode(modus) if the data is factorial orstring and the distribution of variations in the data varies. The table () function can help with the mode(modus) of data\n\nFor simplicity we will drop all null containing rows. The result is a dataset reduced by 12%\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data=df#.drop(['education'],axis=1)\ndata.dropna(axis=0,inplace=True)\n\ndata.describe(include='all')","execution_count":28,"outputs":[{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"              male          age    education  currentSmoker   cigsPerDay  \\\ncount  3656.000000  3656.000000  3656.000000    3656.000000  3656.000000   \nmean      0.443654    49.557440     1.979759       0.489059     9.022155   \nstd       0.496883     8.561133     1.022657       0.499949    11.918869   \nmin       0.000000    32.000000     1.000000       0.000000     0.000000   \n25%       0.000000    42.000000     1.000000       0.000000     0.000000   \n50%       0.000000    49.000000     2.000000       0.000000     0.000000   \n75%       1.000000    56.000000     3.000000       1.000000    20.000000   \nmax       1.000000    70.000000     4.000000       1.000000    70.000000   \n\n            BPMeds  prevalentStroke  prevalentHyp     diabetes      totChol  \\\ncount  3656.000000      3656.000000   3656.000000  3656.000000  3656.000000   \nmean      0.030361         0.005744      0.311543     0.027079   236.873085   \nstd       0.171602         0.075581      0.463187     0.162335    44.096223   \nmin       0.000000         0.000000      0.000000     0.000000   113.000000   \n25%       0.000000         0.000000      0.000000     0.000000   206.000000   \n50%       0.000000         0.000000      0.000000     0.000000   234.000000   \n75%       0.000000         0.000000      1.000000     0.000000   263.250000   \nmax       1.000000         1.000000      1.000000     1.000000   600.000000   \n\n             sysBP        diaBP          BMI    heartRate      glucose  \\\ncount  3656.000000  3656.000000  3656.000000  3656.000000  3656.000000   \nmean    132.368025    82.912062    25.784185    75.730580    81.856127   \nstd      22.092444    11.974825     4.065913    11.982952    23.910128   \nmin      83.500000    48.000000    15.540000    44.000000    40.000000   \n25%     117.000000    75.000000    23.080000    68.000000    71.000000   \n50%     128.000000    82.000000    25.380000    75.000000    78.000000   \n75%     144.000000    90.000000    28.040000    82.000000    87.000000   \nmax     295.000000   142.500000    56.800000   143.000000   394.000000   \n\n        TenYearCHD  \ncount  3656.000000  \nmean      0.152352  \nstd       0.359411  \nmin       0.000000  \n25%       0.000000  \n50%       0.000000  \n75%       0.000000  \nmax       1.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>male</th>\n      <th>age</th>\n      <th>education</th>\n      <th>currentSmoker</th>\n      <th>cigsPerDay</th>\n      <th>BPMeds</th>\n      <th>prevalentStroke</th>\n      <th>prevalentHyp</th>\n      <th>diabetes</th>\n      <th>totChol</th>\n      <th>sysBP</th>\n      <th>diaBP</th>\n      <th>BMI</th>\n      <th>heartRate</th>\n      <th>glucose</th>\n      <th>TenYearCHD</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3656.000000</td>\n      <td>3656.000000</td>\n      <td>3656.000000</td>\n      <td>3656.000000</td>\n      <td>3656.000000</td>\n      <td>3656.000000</td>\n      <td>3656.000000</td>\n      <td>3656.000000</td>\n      <td>3656.000000</td>\n      <td>3656.000000</td>\n      <td>3656.000000</td>\n      <td>3656.000000</td>\n      <td>3656.000000</td>\n      <td>3656.000000</td>\n      <td>3656.000000</td>\n      <td>3656.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.443654</td>\n      <td>49.557440</td>\n      <td>1.979759</td>\n      <td>0.489059</td>\n      <td>9.022155</td>\n      <td>0.030361</td>\n      <td>0.005744</td>\n      <td>0.311543</td>\n      <td>0.027079</td>\n      <td>236.873085</td>\n      <td>132.368025</td>\n      <td>82.912062</td>\n      <td>25.784185</td>\n      <td>75.730580</td>\n      <td>81.856127</td>\n      <td>0.152352</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.496883</td>\n      <td>8.561133</td>\n      <td>1.022657</td>\n      <td>0.499949</td>\n      <td>11.918869</td>\n      <td>0.171602</td>\n      <td>0.075581</td>\n      <td>0.463187</td>\n      <td>0.162335</td>\n      <td>44.096223</td>\n      <td>22.092444</td>\n      <td>11.974825</td>\n      <td>4.065913</td>\n      <td>11.982952</td>\n      <td>23.910128</td>\n      <td>0.359411</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>32.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>113.000000</td>\n      <td>83.500000</td>\n      <td>48.000000</td>\n      <td>15.540000</td>\n      <td>44.000000</td>\n      <td>40.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>42.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>206.000000</td>\n      <td>117.000000</td>\n      <td>75.000000</td>\n      <td>23.080000</td>\n      <td>68.000000</td>\n      <td>71.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>49.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>234.000000</td>\n      <td>128.000000</td>\n      <td>82.000000</td>\n      <td>25.380000</td>\n      <td>75.000000</td>\n      <td>78.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.000000</td>\n      <td>56.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>20.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>263.250000</td>\n      <td>144.000000</td>\n      <td>90.000000</td>\n      <td>28.040000</td>\n      <td>82.000000</td>\n      <td>87.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>70.000000</td>\n      <td>4.000000</td>\n      <td>1.000000</td>\n      <td>70.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>600.000000</td>\n      <td>295.000000</td>\n      <td>142.500000</td>\n      <td>56.800000</td>\n      <td>143.000000</td>\n      <td>394.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"For simplicity we will drop education and all null containing columns. The result is a dataset reduced by 12%\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"category=['male','currentSmoker','BPMeds','prevalentStroke','prevalentHyp','diabetes','education']\ncols=list(data.columns)\ncols.remove('TenYearCHD')\nnumeric=list(set(cols)-set(category))","execution_count":29,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets do some Chisquared test for independance between categorical variables and predictor variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in category:\n    print(\"-------\"+i+\"-------\")\n    contingency_table=pd.crosstab(data[i],data[\"TenYearCHD\"])\n    #print('contingency_table :-\\n',contingency_table)\n\n    Observed_Values = contingency_table.values \n    #print(\"Observed Values :-\\n\",Observed_Values)\n\n    #Expected Values\n    import scipy.stats\n    b=scipy.stats.chi2_contingency(contingency_table)\n    Expected_Values = b[3]\n    #print(\"Expected Values :-\\n\",Expected_Values)\n\n    deg_freedom=b[2]\n    print(\"Degree of Freedom:-\",deg_freedom)\n\n    from scipy.stats import chi2\n    chi_square=sum([(o-e)**2./e for o,e in zip(Observed_Values,Expected_Values)])\n    chi_square_statistic=chi_square[0]+chi_square[1]\n    print(\"chi-square statistic:-\",chi_square_statistic)\n\n    p_value=1-chi2.cdf(x=chi_square_statistic,df=deg_freedom)\n    print('p-value:',p_value)\n\n    if p_value<=0.05:\n        print(\"There is a relationship\")\n    else:\n        print(\"There is no relationship \")","execution_count":30,"outputs":[{"output_type":"stream","text":"-------male-------\nDegree of Freedom:- 1\nchi-square statistic:- 30.77300519507496\np-value: 2.900447715337151e-08\nThere is a relationship\n-------currentSmoker-------\nDegree of Freedom:- 1\nchi-square statistic:- 1.3444080980686755\np-value: 0.24625808474142385\nThere is no relationship \n-------BPMeds-------\nDegree of Freedom:- 1\nchi-square statistic:- 29.03452113804038\np-value: 7.109993427345529e-08\nThere is a relationship\n-------prevalentStroke-------\nDegree of Freedom:- 1\nchi-square statistic:- 8.546916048696804\np-value: 0.0034610809460219327\nThere is a relationship\n-------prevalentHyp-------\nDegree of Freedom:- 1\nchi-square statistic:- 120.51173022673483\np-value: 0.0\nThere is a relationship\n-------diabetes-------\nDegree of Freedom:- 1\nchi-square statistic:- 31.89157153229049\np-value: 1.6302300176462836e-08\nThere is a relationship\n-------education-------\nDegree of Freedom:- 3\nchi-square statistic:- 31.062637414123984\np-value: 8.246210529971876e-07\nThere is a relationship\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"From the above results. All categorical variables except currSmoker has a significant relationship with Heart Disease"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats\nfor i in numeric:\n    print(\"------\"+i+\"--------\")\n    df_anova = data[[\"TenYearCHD\",i]]\n\n    grps = pd.unique(df_anova[\"TenYearCHD\"].values)\n    d_data = {grp:df_anova[i][df_anova[\"TenYearCHD\"] == grp] for grp in grps}\n\n    F, p = stats.f_oneway(d_data[0], d_data[1])\n    print(\"p-value for significance is: \", round(p,4))\n    if p<0.05:\n        print(\"reject null hypothesis\")\n    else:\n        print(\"accept null hypothesis\")","execution_count":31,"outputs":[{"output_type":"stream","text":"------age--------\np-value for significance is:  0.0\nreject null hypothesis\n------cigsPerDay--------\np-value for significance is:  0.0016\nreject null hypothesis\n------diaBP--------\np-value for significance is:  0.0\nreject null hypothesis\n------totChol--------\np-value for significance is:  0.0\nreject null hypothesis\n------sysBP--------\np-value for significance is:  0.0\nreject null hypothesis\n------BMI--------\np-value for significance is:  0.0\nreject null hypothesis\n------heartRate--------\np-value for significance is:  0.2147\naccept null hypothesis\n------glucose--------\np-value for significance is:  0.0\nreject null hypothesis\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Heart rate shows no relation with Heart disease.\nLets see the variation inflation factor for Numeric data"},{"metadata":{},"cell_type":"markdown","source":"Lets take two approaches here.A model with the above filtered variables. One with feature selection by backward elimination."},{"metadata":{},"cell_type":"markdown","source":"Case 1 (backward elimination)\n\nWe feed the dataset without scrutinizing the independant variable and apply backward elimination using p-value to come with a set of variables for which p values are below (0.05)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tools import add_constant\nfrom statsmodels.discrete.discrete_model import Logit\nx=data[cols]\nx = add_constant(x)\ny=data.TenYearCHD\nmodel=Logit(y,x)\nresult=model.fit()\nresult.summary()","execution_count":32,"outputs":[{"output_type":"stream","text":"Optimization terminated successfully.\n         Current function value: 0.376668\n         Iterations 7\n","name":"stdout"},{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                           Logit Regression Results                           \n==============================================================================\nDep. Variable:             TenYearCHD   No. Observations:                 3656\nModel:                          Logit   Df Residuals:                     3640\nMethod:                           MLE   Df Model:                           15\nDate:                Sun, 17 May 2020   Pseudo R-squ.:                  0.1174\nTime:                        12:54:39   Log-Likelihood:                -1377.1\nconverged:                       True   LL-Null:                       -1560.3\nCovariance Type:            nonrobust   LLR p-value:                 8.027e-69\n===================================================================================\n                      coef    std err          z      P>|z|      [0.025      0.975]\n-----------------------------------------------------------------------------------\nconst              -8.3222      0.715    -11.632      0.000      -9.725      -6.920\nmale                0.5551      0.109      5.090      0.000       0.341       0.769\nage                 0.0635      0.007      9.499      0.000       0.050       0.077\neducation          -0.0475      0.049     -0.962      0.336      -0.144       0.049\ncurrentSmoker       0.0709      0.157      0.452      0.651      -0.236       0.378\ncigsPerDay          0.0179      0.006      2.874      0.004       0.006       0.030\nBPMeds              0.1623      0.234      0.692      0.489      -0.297       0.621\nprevalentStroke     0.6935      0.490      1.417      0.157      -0.266       1.653\nprevalentHyp        0.2346      0.138      1.700      0.089      -0.036       0.505\ndiabetes            0.0395      0.315      0.125      0.900      -0.579       0.658\ntotChol             0.0023      0.001      2.062      0.039       0.000       0.005\nsysBP               0.0154      0.004      4.043      0.000       0.008       0.023\ndiaBP              -0.0041      0.006     -0.642      0.521      -0.017       0.008\nBMI                 0.0066      0.013      0.518      0.605      -0.018       0.032\nheartRate          -0.0032      0.004     -0.772      0.440      -0.012       0.005\nglucose             0.0071      0.002      3.189      0.001       0.003       0.012\n===================================================================================\n\"\"\"","text/html":"<table class=\"simpletable\">\n<caption>Logit Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>      <td>TenYearCHD</td>    <th>  No. Observations:  </th>  <td>  3656</td>  \n</tr>\n<tr>\n  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  3640</td>  \n</tr>\n<tr>\n  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    15</td>  \n</tr>\n<tr>\n  <th>Date:</th>            <td>Sun, 17 May 2020</td> <th>  Pseudo R-squ.:     </th>  <td>0.1174</td>  \n</tr>\n<tr>\n  <th>Time:</th>                <td>12:54:39</td>     <th>  Log-Likelihood:    </th> <td> -1377.1</td> \n</tr>\n<tr>\n  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -1560.3</td> \n</tr>\n<tr>\n  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>8.027e-69</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n         <td></td>            <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>const</th>           <td>   -8.3222</td> <td>    0.715</td> <td>  -11.632</td> <td> 0.000</td> <td>   -9.725</td> <td>   -6.920</td>\n</tr>\n<tr>\n  <th>male</th>            <td>    0.5551</td> <td>    0.109</td> <td>    5.090</td> <td> 0.000</td> <td>    0.341</td> <td>    0.769</td>\n</tr>\n<tr>\n  <th>age</th>             <td>    0.0635</td> <td>    0.007</td> <td>    9.499</td> <td> 0.000</td> <td>    0.050</td> <td>    0.077</td>\n</tr>\n<tr>\n  <th>education</th>       <td>   -0.0475</td> <td>    0.049</td> <td>   -0.962</td> <td> 0.336</td> <td>   -0.144</td> <td>    0.049</td>\n</tr>\n<tr>\n  <th>currentSmoker</th>   <td>    0.0709</td> <td>    0.157</td> <td>    0.452</td> <td> 0.651</td> <td>   -0.236</td> <td>    0.378</td>\n</tr>\n<tr>\n  <th>cigsPerDay</th>      <td>    0.0179</td> <td>    0.006</td> <td>    2.874</td> <td> 0.004</td> <td>    0.006</td> <td>    0.030</td>\n</tr>\n<tr>\n  <th>BPMeds</th>          <td>    0.1623</td> <td>    0.234</td> <td>    0.692</td> <td> 0.489</td> <td>   -0.297</td> <td>    0.621</td>\n</tr>\n<tr>\n  <th>prevalentStroke</th> <td>    0.6935</td> <td>    0.490</td> <td>    1.417</td> <td> 0.157</td> <td>   -0.266</td> <td>    1.653</td>\n</tr>\n<tr>\n  <th>prevalentHyp</th>    <td>    0.2346</td> <td>    0.138</td> <td>    1.700</td> <td> 0.089</td> <td>   -0.036</td> <td>    0.505</td>\n</tr>\n<tr>\n  <th>diabetes</th>        <td>    0.0395</td> <td>    0.315</td> <td>    0.125</td> <td> 0.900</td> <td>   -0.579</td> <td>    0.658</td>\n</tr>\n<tr>\n  <th>totChol</th>         <td>    0.0023</td> <td>    0.001</td> <td>    2.062</td> <td> 0.039</td> <td>    0.000</td> <td>    0.005</td>\n</tr>\n<tr>\n  <th>sysBP</th>           <td>    0.0154</td> <td>    0.004</td> <td>    4.043</td> <td> 0.000</td> <td>    0.008</td> <td>    0.023</td>\n</tr>\n<tr>\n  <th>diaBP</th>           <td>   -0.0041</td> <td>    0.006</td> <td>   -0.642</td> <td> 0.521</td> <td>   -0.017</td> <td>    0.008</td>\n</tr>\n<tr>\n  <th>BMI</th>             <td>    0.0066</td> <td>    0.013</td> <td>    0.518</td> <td> 0.605</td> <td>   -0.018</td> <td>    0.032</td>\n</tr>\n<tr>\n  <th>heartRate</th>       <td>   -0.0032</td> <td>    0.004</td> <td>   -0.772</td> <td> 0.440</td> <td>   -0.012</td> <td>    0.005</td>\n</tr>\n<tr>\n  <th>glucose</th>         <td>    0.0071</td> <td>    0.002</td> <td>    3.189</td> <td> 0.001</td> <td>    0.003</td> <td>    0.012</td>\n</tr>\n</table>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"The message box shows it took 10 iterations to fit the best possible model and also shows current function value (objective function). This value is helpful when after certain number of iterations the model wont learn so the objective function remains the same\n\nMaximum Likelihood estimation: To find an optimal way to fit a distribution on the data. the optimal place at which the distribution must be placed to define the data well. Bigger the likelihood higher the probability that our model is correct.\n\nLog likely hood- its almost negative always. Bigger the better\nLL null- log likely hood null\t- log likely hood when there is no independant variable. Aka. useless model\n\nThe comparison between these two metrics gives \nLLR p-value- show how statistically significant the model is compared to LL-NULL\n\nPseudo R squared(McFadden’s R-squared) - somewhere between 0.2 and 0.4 good. Useful only to comapare different variation of same model"},{"metadata":{"trusted":true},"cell_type":"code","source":"cols=data.columns[:-1]\nprint(cols)","execution_count":33,"outputs":[{"output_type":"stream","text":"Index(['male', 'age', 'education', 'currentSmoker', 'cigsPerDay', 'BPMeds',\n       'prevalentStroke', 'prevalentHyp', 'diabetes', 'totChol', 'sysBP',\n       'diaBP', 'BMI', 'heartRate', 'glucose'],\n      dtype='object')\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef back_feature_elem (data_frame,dep_var,col_list):\n    while len(col_list)>0 :\n        x=data[col_list]\n        x = add_constant(x)\n        y=data.TenYearCHD\n        model=Logit(y,x)\n        result=model.fit(disp=0)\n        largest_pvalue=round(result.pvalues,3).nlargest(1)\n        if largest_pvalue[0]<(0.05):\n            return result\n            break\n        else:\n            col_list=col_list.drop(largest_pvalue.index)\n    \nresult=back_feature_elem(data,data.TenYearCHD,cols)\nresult.summary()","execution_count":34,"outputs":[{"output_type":"execute_result","execution_count":34,"data":{"text/plain":"<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                           Logit Regression Results                           \n==============================================================================\nDep. Variable:             TenYearCHD   No. Observations:                 3656\nModel:                          Logit   Df Residuals:                     3649\nMethod:                           MLE   Df Model:                            6\nDate:                Sun, 17 May 2020   Pseudo R-squ.:                  0.1147\nTime:                        12:54:39   Log-Likelihood:                -1381.2\nconverged:                       True   LL-Null:                       -1560.3\nCovariance Type:            nonrobust   LLR p-value:                 2.885e-74\n==============================================================================\n                 coef    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -9.1298      0.476    -19.199      0.000     -10.062      -8.198\nmale           0.5614      0.107      5.255      0.000       0.352       0.771\nage            0.0659      0.006     10.254      0.000       0.053       0.078\ncigsPerDay     0.0192      0.004      4.604      0.000       0.011       0.027\ntotChol        0.0023      0.001      2.024      0.043    7.16e-05       0.004\nsysBP          0.0175      0.002      8.159      0.000       0.013       0.022\nglucose        0.0073      0.002      4.342      0.000       0.004       0.011\n==============================================================================\n\"\"\"","text/html":"<table class=\"simpletable\">\n<caption>Logit Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>      <td>TenYearCHD</td>    <th>  No. Observations:  </th>  <td>  3656</td>  \n</tr>\n<tr>\n  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  3649</td>  \n</tr>\n<tr>\n  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     6</td>  \n</tr>\n<tr>\n  <th>Date:</th>            <td>Sun, 17 May 2020</td> <th>  Pseudo R-squ.:     </th>  <td>0.1147</td>  \n</tr>\n<tr>\n  <th>Time:</th>                <td>12:54:39</td>     <th>  Log-Likelihood:    </th> <td> -1381.2</td> \n</tr>\n<tr>\n  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -1560.3</td> \n</tr>\n<tr>\n  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>2.885e-74</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n       <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>const</th>      <td>   -9.1298</td> <td>    0.476</td> <td>  -19.199</td> <td> 0.000</td> <td>  -10.062</td> <td>   -8.198</td>\n</tr>\n<tr>\n  <th>male</th>       <td>    0.5614</td> <td>    0.107</td> <td>    5.255</td> <td> 0.000</td> <td>    0.352</td> <td>    0.771</td>\n</tr>\n<tr>\n  <th>age</th>        <td>    0.0659</td> <td>    0.006</td> <td>   10.254</td> <td> 0.000</td> <td>    0.053</td> <td>    0.078</td>\n</tr>\n<tr>\n  <th>cigsPerDay</th> <td>    0.0192</td> <td>    0.004</td> <td>    4.604</td> <td> 0.000</td> <td>    0.011</td> <td>    0.027</td>\n</tr>\n<tr>\n  <th>totChol</th>    <td>    0.0023</td> <td>    0.001</td> <td>    2.024</td> <td> 0.043</td> <td> 7.16e-05</td> <td>    0.004</td>\n</tr>\n<tr>\n  <th>sysBP</th>      <td>    0.0175</td> <td>    0.002</td> <td>    8.159</td> <td> 0.000</td> <td>    0.013</td> <td>    0.022</td>\n</tr>\n<tr>\n  <th>glucose</th>    <td>    0.0073</td> <td>    0.002</td> <td>    4.342</td> <td> 0.000</td> <td>    0.004</td> <td>    0.011</td>\n</tr>\n</table>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Feature Selection: Backward elemination (P-value approach)\nTakes in the dataframe, the dependent variable and a list of column names, \nruns the regression repeatedly eliminating feature with the highest\nP-value above alpha one at a time and returns the regression summary \nwith all p-values below alpha\n\nLets interpret the coefficients of the variables.\nThe exponential off the coeffcients give the odds ratio."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.exp(result.params))","execution_count":42,"outputs":[{"output_type":"stream","text":"const         0.000108\nmale          1.753206\nage           1.068116\ncigsPerDay    1.019412\ntotChol       1.002275\nsysBP         1.017689\nglucose       1.007307\ndtype: float64\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"the values mean that\nfor males there is a 75% (1.75-1 =0.75) higher chances of heart disease than for females\n\nsimilarly,\nfor 1 year increase in age there is 6.8% higher chance of getting heart disease.\n\nand so on..\n\nLets do some predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets get the confusion matrix based on statsmodel\n\nconf_sm=pd.DataFrame(result.pred_table())\nconf_sm.columns=['predicted 0','predicted 1']\nconf_sm=conf_sm.rename(index={0:'Actual 0',1:'Actual 1'})\nconf_sm","execution_count":46,"outputs":[{"output_type":"execute_result","execution_count":46,"data":{"text/plain":"          predicted 0  predicted 1\nActual 0       3076.0         23.0\nActual 1        515.0         42.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>predicted 0</th>\n      <th>predicted 1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Actual 0</th>\n      <td>3076.0</td>\n      <td>23.0</td>\n    </tr>\n    <tr>\n      <th>Actual 1</th>\n      <td>515.0</td>\n      <td>42.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train split\n\nimport sklearn\nnew_features=data[['age','male','cigsPerDay','totChol','sysBP','glucose','TenYearCHD']]\nx=new_features.iloc[:,:-1]\ny=new_features.iloc[:,-1]\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.20,random_state=5)\n\nfrom sklearn.linear_model import LogisticRegression\nlogreg=LogisticRegression()\nlogreg.fit(x_train,y_train)\ny_pred=logreg.predict(x_test)\n\n\nfrom sklearn import metrics\nconfusion_matrix = metrics.confusion_matrix(y_test,y_pred)\n\nconf=pd.DataFrame(confusion_matrix)\nconf.columns=['predicted 0','predicted 1']\nconf=conf.rename(index={0:'Actual 0',1:'Actual 1'})\nprint(conf)\n\nprint(\"model accuracy:\")\nprint(sklearn.metrics.accuracy_score(y_test,y_pred))","execution_count":52,"outputs":[{"output_type":"stream","text":"          predicted 0  predicted 1\nActual 0          620            3\nActual 1           97           12\nmodel accuracy:\n0.8633879781420765\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"The model predicts the correct output 86.3% of the time\n\n\nCase 2-\n\nLets try for model with feature selection done manually. Based on our hypothesis testing. We rejected currentSmoker and heart rate to be of significant predictor."},{"metadata":{"trusted":true},"cell_type":"code","source":"x=data.drop(['TenYearCHD','currentSmoker','heartRate'],axis=1)\nx=add_constant(x)\ny=data.TenYearCHD\nmodel=Logit(y,x)\nresult=model.fit(disp=0)\nresult.summary()","execution_count":56,"outputs":[{"output_type":"execute_result","execution_count":56,"data":{"text/plain":"<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                           Logit Regression Results                           \n==============================================================================\nDep. Variable:             TenYearCHD   No. Observations:                 3656\nModel:                          Logit   Df Residuals:                     3642\nMethod:                           MLE   Df Model:                           13\nDate:                Sun, 17 May 2020   Pseudo R-squ.:                  0.1171\nTime:                        14:27:58   Log-Likelihood:                -1377.5\nconverged:                       True   LL-Null:                       -1560.3\nCovariance Type:            nonrobust   LLR p-value:                 4.151e-70\n===================================================================================\n                      coef    std err          z      P>|z|      [0.025      0.975]\n-----------------------------------------------------------------------------------\nconst              -8.4739      0.660    -12.834      0.000      -9.768      -7.180\nmale                0.5649      0.108      5.218      0.000       0.353       0.777\nage                 0.0636      0.007      9.563      0.000       0.051       0.077\neducation          -0.0460      0.049     -0.931      0.352      -0.143       0.051\ncigsPerDay          0.0196      0.004      4.664      0.000       0.011       0.028\nBPMeds              0.1701      0.234      0.727      0.467      -0.289       0.629\nprevalentStroke     0.7015      0.489      1.435      0.151      -0.257       1.660\nprevalentHyp        0.2286      0.138      1.659      0.097      -0.041       0.499\ndiabetes            0.0399      0.315      0.127      0.899      -0.577       0.657\ntotChol             0.0023      0.001      2.013      0.044    6.01e-05       0.004\nsysBP               0.0153      0.004      4.016      0.000       0.008       0.023\ndiaBP              -0.0044      0.006     -0.685      0.494      -0.017       0.008\nBMI                 0.0058      0.013      0.460      0.645      -0.019       0.031\nglucose             0.0070      0.002      3.141      0.002       0.003       0.011\n===================================================================================\n\"\"\"","text/html":"<table class=\"simpletable\">\n<caption>Logit Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>      <td>TenYearCHD</td>    <th>  No. Observations:  </th>  <td>  3656</td>  \n</tr>\n<tr>\n  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  3642</td>  \n</tr>\n<tr>\n  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    13</td>  \n</tr>\n<tr>\n  <th>Date:</th>            <td>Sun, 17 May 2020</td> <th>  Pseudo R-squ.:     </th>  <td>0.1171</td>  \n</tr>\n<tr>\n  <th>Time:</th>                <td>14:27:58</td>     <th>  Log-Likelihood:    </th> <td> -1377.5</td> \n</tr>\n<tr>\n  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -1560.3</td> \n</tr>\n<tr>\n  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>4.151e-70</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n         <td></td>            <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>const</th>           <td>   -8.4739</td> <td>    0.660</td> <td>  -12.834</td> <td> 0.000</td> <td>   -9.768</td> <td>   -7.180</td>\n</tr>\n<tr>\n  <th>male</th>            <td>    0.5649</td> <td>    0.108</td> <td>    5.218</td> <td> 0.000</td> <td>    0.353</td> <td>    0.777</td>\n</tr>\n<tr>\n  <th>age</th>             <td>    0.0636</td> <td>    0.007</td> <td>    9.563</td> <td> 0.000</td> <td>    0.051</td> <td>    0.077</td>\n</tr>\n<tr>\n  <th>education</th>       <td>   -0.0460</td> <td>    0.049</td> <td>   -0.931</td> <td> 0.352</td> <td>   -0.143</td> <td>    0.051</td>\n</tr>\n<tr>\n  <th>cigsPerDay</th>      <td>    0.0196</td> <td>    0.004</td> <td>    4.664</td> <td> 0.000</td> <td>    0.011</td> <td>    0.028</td>\n</tr>\n<tr>\n  <th>BPMeds</th>          <td>    0.1701</td> <td>    0.234</td> <td>    0.727</td> <td> 0.467</td> <td>   -0.289</td> <td>    0.629</td>\n</tr>\n<tr>\n  <th>prevalentStroke</th> <td>    0.7015</td> <td>    0.489</td> <td>    1.435</td> <td> 0.151</td> <td>   -0.257</td> <td>    1.660</td>\n</tr>\n<tr>\n  <th>prevalentHyp</th>    <td>    0.2286</td> <td>    0.138</td> <td>    1.659</td> <td> 0.097</td> <td>   -0.041</td> <td>    0.499</td>\n</tr>\n<tr>\n  <th>diabetes</th>        <td>    0.0399</td> <td>    0.315</td> <td>    0.127</td> <td> 0.899</td> <td>   -0.577</td> <td>    0.657</td>\n</tr>\n<tr>\n  <th>totChol</th>         <td>    0.0023</td> <td>    0.001</td> <td>    2.013</td> <td> 0.044</td> <td> 6.01e-05</td> <td>    0.004</td>\n</tr>\n<tr>\n  <th>sysBP</th>           <td>    0.0153</td> <td>    0.004</td> <td>    4.016</td> <td> 0.000</td> <td>    0.008</td> <td>    0.023</td>\n</tr>\n<tr>\n  <th>diaBP</th>           <td>   -0.0044</td> <td>    0.006</td> <td>   -0.685</td> <td> 0.494</td> <td>   -0.017</td> <td>    0.008</td>\n</tr>\n<tr>\n  <th>BMI</th>             <td>    0.0058</td> <td>    0.013</td> <td>    0.460</td> <td> 0.645</td> <td>   -0.019</td> <td>    0.031</td>\n</tr>\n<tr>\n  <th>glucose</th>         <td>    0.0070</td> <td>    0.002</td> <td>    3.141</td> <td> 0.002</td> <td>    0.003</td> <td>    0.011</td>\n</tr>\n</table>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Removing all insignificant variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"x=data.drop(['TenYearCHD','currentSmoker','heartRate','glucose','prevalentStroke','education','BPMeds','prevalentHyp','diabetes','diaBP','BMI'],axis=1)\nx=add_constant(x)\ny=data.TenYearCHD\nmodel=Logit(y,x)\nresult=model.fit(disp=0)\nresult.summary()","execution_count":57,"outputs":[{"output_type":"execute_result","execution_count":57,"data":{"text/plain":"<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                           Logit Regression Results                           \n==============================================================================\nDep. Variable:             TenYearCHD   No. Observations:                 3656\nModel:                          Logit   Df Residuals:                     3650\nMethod:                           MLE   Df Model:                            5\nDate:                Sun, 17 May 2020   Pseudo R-squ.:                  0.1087\nTime:                        14:30:19   Log-Likelihood:                -1390.7\nconverged:                       True   LL-Null:                       -1560.3\nCovariance Type:            nonrobust   LLR p-value:                 3.803e-71\n==============================================================================\n                 coef    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -8.6872      0.459    -18.909      0.000      -9.588      -7.787\nmale           0.5690      0.106      5.344      0.000       0.360       0.778\nage            0.0670      0.006     10.464      0.000       0.054       0.079\ncigsPerDay     0.0184      0.004      4.434      0.000       0.010       0.027\ntotChol        0.0023      0.001      2.073      0.038       0.000       0.005\nsysBP          0.0183      0.002      8.551      0.000       0.014       0.022\n==============================================================================\n\"\"\"","text/html":"<table class=\"simpletable\">\n<caption>Logit Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>      <td>TenYearCHD</td>    <th>  No. Observations:  </th>  <td>  3656</td>  \n</tr>\n<tr>\n  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  3650</td>  \n</tr>\n<tr>\n  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     5</td>  \n</tr>\n<tr>\n  <th>Date:</th>            <td>Sun, 17 May 2020</td> <th>  Pseudo R-squ.:     </th>  <td>0.1087</td>  \n</tr>\n<tr>\n  <th>Time:</th>                <td>14:30:19</td>     <th>  Log-Likelihood:    </th> <td> -1390.7</td> \n</tr>\n<tr>\n  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -1560.3</td> \n</tr>\n<tr>\n  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>3.803e-71</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n       <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>const</th>      <td>   -8.6872</td> <td>    0.459</td> <td>  -18.909</td> <td> 0.000</td> <td>   -9.588</td> <td>   -7.787</td>\n</tr>\n<tr>\n  <th>male</th>       <td>    0.5690</td> <td>    0.106</td> <td>    5.344</td> <td> 0.000</td> <td>    0.360</td> <td>    0.778</td>\n</tr>\n<tr>\n  <th>age</th>        <td>    0.0670</td> <td>    0.006</td> <td>   10.464</td> <td> 0.000</td> <td>    0.054</td> <td>    0.079</td>\n</tr>\n<tr>\n  <th>cigsPerDay</th> <td>    0.0184</td> <td>    0.004</td> <td>    4.434</td> <td> 0.000</td> <td>    0.010</td> <td>    0.027</td>\n</tr>\n<tr>\n  <th>totChol</th>    <td>    0.0023</td> <td>    0.001</td> <td>    2.073</td> <td> 0.038</td> <td>    0.000</td> <td>    0.005</td>\n</tr>\n<tr>\n  <th>sysBP</th>      <td>    0.0183</td> <td>    0.002</td> <td>    8.551</td> <td> 0.000</td> <td>    0.014</td> <td>    0.022</td>\n</tr>\n</table>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train split\n\nimport sklearn\nnew_features=data[['age','male','cigsPerDay','totChol','sysBP','TenYearCHD']]\nx=new_features.iloc[:,:-1]\ny=new_features.iloc[:,-1]\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.20,random_state=5)\n#print(x_test)\nfrom sklearn.linear_model import LogisticRegression\nlogreg=LogisticRegression()\nlogreg.fit(x_train,y_train)\ny_pred=logreg.predict(x_test)\n\nfrom sklearn import metrics\nconfusion_matrix = metrics.confusion_matrix(y_test,y_pred)\n\nconf=pd.DataFrame(confusion_matrix)\nconf.columns=['predicted 0','predicted 1']\nconf=conf.rename(index={0:'Actual 0',1:'Actual 1'})\nprint(conf)\n\nprint(\"model accuracy:\")\nprint(sklearn.metrics.accuracy_score(y_test,y_pred))","execution_count":61,"outputs":[{"output_type":"stream","text":"[-8.93217051]\n          predicted 0  predicted 1\nActual 0          622            1\nActual 1           99           10\nmodel accuracy:\n0.8633879781420765\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"There is only slight difference in accuracy between the two models."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}