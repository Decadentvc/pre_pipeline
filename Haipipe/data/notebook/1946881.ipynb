{"cells":[{"metadata":{"_uuid":"53cbdcd0e7eca6a41180a8dc68af0152a1ec7460"},"cell_type":"markdown","source":"# ** Introduction **\n\n### Hello, in this notebook I will do some experiments to figure out the best Machine Learning algorithm on this data and try to tune them to get highest success.  After tuning I will compare them to find best one of the following 6 models.\n\n### <a href=\"#eda\">EDA</a>\n### <a href=\"#visual\">Visual EDA</a>\n### <a href=\"#prep\">Data Preprocess</a>\n\n### <a href=\"#mls\">Machine Learning Models</a>\n*  <a href=\"#lr\"> Logistic Regression</a>\n*  <a href=\"#knn\"> KNN</a>\n*  <a href=\"#svm\">SVM</a>\n*  <a href=\"#rf\">Random Forest</a>\n*  <a href=\"#dc\">Decision Tree</a>\n*  <a href=\"#nb\">Naive Bayes</a>\n\n### <a href=\"#res\">Results and Comparisons</a>"},{"metadata":{"_uuid":"eb32d814d5e669224e730ba418731a91ceb8af7f"},"cell_type":"markdown","source":"<a id=\"eda\"></a>\n## ** Exploratory Data Analysis **"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cb5166fd5b184591a76f72985745ca44b35586fe"},"cell_type":"markdown","source":"### Loading the dataset"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"DataFrame = pd.read_csv(\"../input/pulsar_stars.csv\")  ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"efab51a86fa3628b7f0ac0a118a04ee0bf51f028"},"cell_type":"markdown","source":"### Investigating the Dataset"},{"metadata":{"trusted":true,"_uuid":"494ee486aee61bd61b09b913314946fe31b13d1a"},"cell_type":"code","source":"DataFrame.head()    # first 5 rows of whole columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d366bac0d05a0cbd9e72c9fd4760f55c1afd674"},"cell_type":"markdown","source":"### Looking to Dtypes and amounts of values"},{"metadata":{"trusted":true,"_uuid":"dc36dedaf65e6a98eaff32371a5fef3a4b0d6c09"},"cell_type":"code","source":"DataFrame.info()   # information about data types and amount of non-null rows of our Dataset","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b5408f1280e04fcad2dd05a88456471209f3786d"},"cell_type":"markdown","source":"(Bonus) data types are all numeric and non-null, I don't need to do any transformations or cleaning."},{"metadata":{"_uuid":"6e292e7fedcb985be663ec6b2d2a535ae6d00072"},"cell_type":"markdown","source":"### Statistical Investigation"},{"metadata":{"trusted":true,"_uuid":"c0fde1ddaade4b70481e95e330e9aa601c5d6b71"},"cell_type":"code","source":"DataFrame.describe()   # statistical information about our data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"09543f0516e12b52bb3a27a23abbb05e59ffa6d2"},"cell_type":"code","source":"DataFrame.corr()    # correlation between fields","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fec199a7bfaed7babb12d4adb880f438cf140e6a"},"cell_type":"markdown","source":"<a id=\"visual\"></a>\n## ** Visual EDA **"},{"metadata":{"trusted":true,"_uuid":"bf5497f44527ad18e818f19402ca5dc4f7f15e6e"},"cell_type":"code","source":"import matplotlib.pyplot as plt    # basic plotting library\nimport seaborn as sns              # more advanced visual plotting library","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0bd0a023b60fc466e24bb51759c40b11cd162ecd"},"cell_type":"markdown","source":"### ** PairPlot **  (each column is compared the others and itself)"},{"metadata":{"trusted":true,"_uuid":"bff132364220d76225e2f7ee0a9b50cc7ef0ccc7"},"cell_type":"code","source":"sns.pairplot(data=DataFrame,\n             palette=\"husl\",\n             hue=\"target_class\",\n             vars=[\" Mean of the integrated profile\",\n                   \" Excess kurtosis of the integrated profile\",\n                   \" Skewness of the integrated profile\",\n                   \" Mean of the DM-SNR curve\",\n                   \" Excess kurtosis of the DM-SNR curve\",\n                   \" Skewness of the DM-SNR curve\"])\n\nplt.suptitle(\"PairPlot of Data Without Std. Dev. Fields\",fontsize=18)\n\nplt.tight_layout()\nplt.show()   # pairplot without standard deviaton fields of data","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"be70019dbed13080add87197f6f067644e5f9dc9"},"cell_type":"markdown","source":"we can see that our data is quite separable on most of the columns"},{"metadata":{"_uuid":"0b2ae331bf73e58d561b8df1d35406e2a324b0fe"},"cell_type":"markdown","source":"### ** Correlation HeatMap **"},{"metadata":{"trusted":true,"_uuid":"1998f1f0362746f3b3767ad3da167ea4f57cf9ac"},"cell_type":"code","source":"plt.figure(figsize=(16,12))\nsns.heatmap(data=DataFrame.corr(),annot=True,cmap=\"bone\",linewidths=1,fmt=\".2f\",linecolor=\"gray\")\nplt.title(\"Correlation Map\",fontsize=20)\nplt.tight_layout()\nplt.show()      # lightest and darkest cells are most correlated ones","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4a55573841a2820f3d1fc55df4b55ce946422a49"},"cell_type":"markdown","source":"Most of our Columns are already related or derived from one or another. And we can see it clearly on some Cells above"},{"metadata":{"_uuid":"9e147384557a16ccbee1431d761743cfd28c6eff"},"cell_type":"markdown","source":"### ** ViolinPlot **  (act as a boxplot but we can see amounts too)"},{"metadata":{"trusted":true,"_uuid":"b83877bcc8ad146ce642ed288f31b73e57e787ea"},"cell_type":"code","source":"plt.figure(figsize=(16,10))\n\nplt.subplot(2,2,1)\nsns.violinplot(data=DataFrame,y=\" Mean of the integrated profile\",x=\"target_class\")\n\nplt.subplot(2,2,2)\nsns.violinplot(data=DataFrame,y=\" Mean of the DM-SNR curve\",x=\"target_class\")\n\nplt.subplot(2,2,3)\nsns.violinplot(data=DataFrame,y=\" Standard deviation of the integrated profile\",x=\"target_class\")\n\nplt.subplot(2,2,4)\nsns.violinplot(data=DataFrame,y=\" Standard deviation of the DM-SNR curve\",x=\"target_class\")\n\n\nplt.suptitle(\"ViolinPlot\",fontsize=20)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eb5dd47c8ba9a9f0aa49e81b98a1f814b263a76a"},"cell_type":"markdown","source":"We can see that our data has different kind of distributions which is helpful for training our models."},{"metadata":{"_uuid":"45e5a8eb1380482cfad4b8f2f84867908dafb639"},"cell_type":"markdown","source":"<a id=\"prep\"></a>\n## ** Data PreProcessing **"},{"metadata":{"_uuid":"1905a234bfec00cedcb3a742e37615fc7a360871"},"cell_type":"markdown","source":"### Splitting the Feature and Label fields"},{"metadata":{"trusted":true,"_uuid":"6d29e6ba4773eaf69edef6724131f09fc1b6edea"},"cell_type":"code","source":"labels = DataFrame.target_class.values\n\nDataFrame.drop([\"target_class\"],axis=1,inplace=True)\n\nfeatures = DataFrame.values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe401cf076b149aca0f981a6d20eedf96e39aaa1"},"cell_type":"markdown","source":"### Scaling the Features  "},{"metadata":{"trusted":true,"_uuid":"38324061d2d3639105e03b61f35e3dcda1fb8333"},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0,1))\n\nfeatures_scaled = scaler.fit_transform(features)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b4cdf2923370fc701e43e6991477ed45f0bf64b5"},"cell_type":"markdown","source":"###  Splitting the Train and the Test rows"},{"metadata":{"trusted":true,"_uuid":"8bfaeff1399d16335ecbd894c68b36ee54963333"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(features_scaled,labels,test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"12be99625877af13d7578282db9662168e319148"},"cell_type":"markdown","source":"## ** Machine Learning Models **\n<a id=\"mls\"></a>"},{"metadata":{"_uuid":"0f005624825dfb9263eed444f75de40c959d61b7"},"cell_type":"markdown","source":"<a id=\"lr\"></a>\n### ** Logistic Regression **"},{"metadata":{"trusted":true,"_uuid":"1c47cd75e936d40ba267e4d9ab2e838851563522"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr_model = LogisticRegression(random_state=42,solver=\"liblinear\",C=1.6,penalty=\"l1\")\n\nlr_model.fit(x_train,y_train)\n\ny_head_lr = lr_model.predict(x_test)\n\nlr_score = lr_model.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"79741e751b2efc61d46e359b675c814a52a80589"},"cell_type":"markdown","source":"<a id=\"dc\"></a>\n### ** Decision Tree Classifier **"},{"metadata":{"trusted":true,"_uuid":"e37926fac2b81a5e8666bd4490cfd002b69f157c"},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndc_model = DecisionTreeClassifier(random_state=42)\n\ndc_model.fit(x_train,y_train)\n\ny_head_dc = dc_model.predict(x_test)\n\ndc_score = dc_model.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e37b758fd85e1076e9ef9b9eab4086a485ecb402"},"cell_type":"markdown","source":"<a id=\"rf\"></a>\n### ** Random Forest Classifier **"},{"metadata":{"trusted":true,"_uuid":"4c1584c61f74b3a38ff61eae37a3c3d1e3f6a080"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrfc_model = RandomForestClassifier(n_estimators=37,random_state=42,max_leaf_nodes=200,criterion=\"entropy\")\n\nrfc_model.fit(x_train,y_train)\n\ny_head_rfc = rfc_model.predict(x_test)\n\nrfc_score = rfc_model.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8b95000beb1f5a432c48a949bbc9cff2f45ef810"},"cell_type":"markdown","source":"   <a id=\"nb\"></a>\n  ### ** Naive Bayes Classifier **"},{"metadata":{"trusted":true,"_uuid":"a8099dd0342248e2745bdfee79dd8870b6dc4e8e"},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nnb_model = GaussianNB()\n\nnb_model.fit(x_train,y_train)\n\ny_head_nb = nb_model.predict(x_test)\n\nnb_score = nb_model.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"00a5bfa763b029195fdde56b1afa4708a270ed8e"},"cell_type":"markdown","source":"<a id=\"knn\"></a>\n### ** K Nearest Neighbors **"},{"metadata":{"trusted":true,"_uuid":"b1d84dd2f9933540dec57e8e5094422d527032a0"},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn_model = KNeighborsClassifier(n_neighbors=7,weights=\"distance\")\n\nknn_model.fit(x_train,y_train)\n\ny_head_knn = knn_model.predict(x_test)\n\nknn_score = knn_model.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fdfeccd73c1d7ff21f7d4bef37d1e32c89c88899"},"cell_type":"markdown","source":"<a id=\"svm\"></a>\n### ** Support Vector Machine **\n"},{"metadata":{"trusted":true,"_uuid":"8cc5bcb8314bd16b9c714361b7b813ef9df7a6a6"},"cell_type":"code","source":"from sklearn.svm import SVC\nsvm_model = SVC(random_state=42,C=250,gamma=1.6,kernel=\"poly\",probability=True)\n\nsvm_model.fit(x_train,y_train)\n\ny_head_svm = svm_model.predict(x_test)\n\nsvm_score = svm_model.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc4e5eadc52bd87c5f449ba57f6fcd4f4053af1d"},"cell_type":"markdown","source":"<a id=\"res\"></a>\n## ** Model Evaluating **"},{"metadata":{"trusted":true,"_uuid":"e26d6edc4828dfd2b7888c0ed88f908c067afcf7"},"cell_type":"markdown","source":"### ** Confusion Matrix **"},{"metadata":{"trusted":true,"_uuid":"5a7a18b168f114d53e1728680e338e83f63defda"},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ncm_lr = confusion_matrix(y_test,y_head_lr)\ncm_dc = confusion_matrix(y_test,y_head_dc)\ncm_knn = confusion_matrix(y_test,y_head_knn)\ncm_nb = confusion_matrix(y_test,y_head_nb)\ncm_rfc = confusion_matrix(y_test,y_head_rfc)\ncm_svm = confusion_matrix(y_test,y_head_svm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"01b06dba1c2c97855799dfd9d7f18d8aef51dde9"},"cell_type":"code","source":"plt.figure(figsize=(24,12))\n\nplt.suptitle(\"Confusion Matrixes\",fontsize=24)\n\nplt.subplot(2,3,1)\nplt.title(\"Logistic Regression Confusion Matrix\")\nsns.heatmap(cm_lr,cbar=False,annot=True,cmap=\"CMRmap_r\",fmt=\"d\")\n\nplt.subplot(2,3,2)\nplt.title(\"Decision Tree Classifier Confusion Matrix\")\nsns.heatmap(cm_dc,cbar=False,annot=True,cmap=\"CMRmap_r\",fmt=\"d\")\n\nplt.subplot(2,3,3)\nplt.title(\"K Nearest Neighbors Confusion Matrix\")\nsns.heatmap(cm_knn,cbar=False,annot=True,cmap=\"CMRmap_r\",fmt=\"d\")\n\nplt.subplot(2,3,4)\nplt.title(\"Naive Bayes Confusion Matrix\")\nsns.heatmap(cm_nb,cbar=False,annot=True,cmap=\"CMRmap_r\",fmt=\"d\")\n\nplt.subplot(2,3,5)\nplt.title(\"Random Forest Confusion Matrix\")\nsns.heatmap(cm_rfc,cbar=False,annot=True,cmap=\"CMRmap_r\",fmt=\"d\")\n\nplt.subplot(2,3,6)\nplt.title(\"Support Vector Machine Confusion Matrix\")\nsns.heatmap(cm_svm,cbar=False,annot=True,cmap=\"CMRmap_r\",fmt=\"d\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d97925a9dd6f11f24a9570d4b22650fac9f30c3e"},"cell_type":"markdown","source":"if we compare total mistakes:  RandomForest, SVM, KNN seem to be best for this dataset"},{"metadata":{"trusted":true,"_uuid":"843827d987c600e848479d59f38b29c74a4de7e8"},"cell_type":"markdown","source":"### ** Bar Chart Comparison  ** "},{"metadata":{"trusted":true,"_uuid":"803deddced282dea02d12d649eb9cda90835ab38"},"cell_type":"code","source":"algorithms = (\"Logistic Regression\",\"Decision Tree\",\"Random Forest\",\"K Nearest Neighbors\",\"Naive Bayes\",\"Support Vector Machine\")\nscores = (lr_score,dc_score,rfc_score,knn_score,nb_score,svm_score)\ny_pos = np.arange(1,7)\ncolors = (\"red\",\"gray\",\"purple\",\"green\",\"orange\",\"blue\")\n\nplt.figure(figsize=(24,12))\nplt.xticks(y_pos,algorithms,fontsize=18)\nplt.yticks(np.arange(0.00, 1.01, step=0.01))\nplt.ylim(0.90,1.00)\nplt.bar(y_pos,scores,color=colors)\nplt.grid()\nplt.suptitle(\"Bar Chart Comparison of Models\",fontsize=24)\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"26e711675011295780084f383aa3cd446bb8dffe"},"cell_type":"markdown","source":"if we look at the graph and check the scores, LogisticRegression, RandomForest and SVM are better than the others."},{"metadata":{"_uuid":"5b3c2adff34892d5c800e64bb446fad0e7c8f49c"},"cell_type":"markdown","source":"# ** Conclusion **"},{"metadata":{"_uuid":"f95ff5a6f7f1940eb96d0eee217927e99c1fc7ea"},"cell_type":"markdown","source":"### After my tests I see that:\n### RandomForest and SVM are Overall winnners in my case above.\nBut all of these 6 models did a great job on predicting "},{"metadata":{"trusted":true,"_uuid":"d8438d143588d6a75f65b42391b08721071d9647"},"cell_type":"code","source":"# thanks for reading. Votes, Comments and Advices are all welcome :) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e93a7900ab1f1f21d30691788255a9ad9f17d1d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2b7014b37e8a2a925fd08a37d31ab9eb86fd063e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}