{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/iris-dataset/Iris.csv\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Load the dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"iris_data = pd.read_csv('/kaggle/input/iris-dataset/Iris.csv')\nprint(iris_data.shape)\nprint(iris_data.head())","execution_count":2,"outputs":[{"output_type":"stream","text":"(150, 6)\n   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n0   1            5.1           3.5            1.4           0.2  Iris-setosa\n1   2            4.9           3.0            1.4           0.2  Iris-setosa\n2   3            4.7           3.2            1.3           0.2  Iris-setosa\n3   4            4.6           3.1            1.5           0.2  Iris-setosa\n4   5            5.0           3.6            1.4           0.2  Iris-setosa\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"We remove the Id column as it has no significance on determining the class labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"iris_data.drop('Id',inplace=True,axis=1)\nprint(iris_data.head())","execution_count":4,"outputs":[{"output_type":"stream","text":"   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n0            5.1           3.5            1.4           0.2  Iris-setosa\n1            4.9           3.0            1.4           0.2  Iris-setosa\n2            4.7           3.2            1.3           0.2  Iris-setosa\n3            4.6           3.1            1.5           0.2  Iris-setosa\n4            5.0           3.6            1.4           0.2  Iris-setosa\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**Let us see the class distribution in the dataset. We can use the value_counts function to get the count of unique values for a given column**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(iris_data['Species'].value_counts())","execution_count":5,"outputs":[{"output_type":"stream","text":"Iris-setosa        50\nIris-virginica     50\nIris-versicolor    50\nName: Species, dtype: int64\n","name":"stdout"}]},{"metadata":{},"cell_type":"raw","source":"There are 3 classes each with 50 samples(perfectly balanced). Let us check for presence of missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"iris_data.isnull().sum()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"SepalLengthCm    0\nSepalWidthCm     0\nPetalLengthCm    0\nPetalWidthCm     0\nSpecies          0\ndtype: int64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"That's great! There are no missing values in the dataset"},{"metadata":{},"cell_type":"markdown","source":"# Partition the dataset into features and labels"},{"metadata":{},"cell_type":"markdown","source":"**We need to shuffle our dataset as the examples are ordered by classes. Training without shuffling the dataset will lead to poor generalization**"},{"metadata":{"trusted":true},"cell_type":"code","source":"iris_data_shuffled = iris_data.sample(frac=1).reset_index(drop=True)\nprint(iris_data_shuffled)","execution_count":7,"outputs":[{"output_type":"stream","text":"     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm          Species\n0              7.7           3.8            6.7           2.2   Iris-virginica\n1              5.7           2.8            4.1           1.3  Iris-versicolor\n2              5.4           3.7            1.5           0.2      Iris-setosa\n3              4.8           3.4            1.9           0.2      Iris-setosa\n4              4.8           3.0            1.4           0.1      Iris-setosa\n..             ...           ...            ...           ...              ...\n145            6.5           2.8            4.6           1.5  Iris-versicolor\n146            7.0           3.2            4.7           1.4  Iris-versicolor\n147            7.7           2.8            6.7           2.0   Iris-virginica\n148            5.6           2.9            3.6           1.3  Iris-versicolor\n149            6.7           3.0            5.0           1.7  Iris-versicolor\n\n[150 rows x 5 columns]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**we will create a new dataframe which consists of the 4 features and another dataframe which consists of the class labels**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop the Species column. Note that we are not doing it inplace so the original dataframe will not be modified\ntrain_x = iris_data_shuffled.drop('Species',axis=1)\nprint(train_x.head())","execution_count":10,"outputs":[{"output_type":"stream","text":"   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n0            7.7           3.8            6.7           2.2\n1            5.7           2.8            4.1           1.3\n2            5.4           3.7            1.5           0.2\n3            4.8           3.4            1.9           0.2\n4            4.8           3.0            1.4           0.1\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_y = iris_data_shuffled['Species']\nprint(train_y.head())","execution_count":17,"outputs":[{"output_type":"stream","text":"0     Iris-virginica\n1    Iris-versicolor\n2        Iris-setosa\n3        Iris-setosa\n4        Iris-setosa\nName: Species, dtype: object\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":" **Let us convert the labels into numeric values. We use LabelEncoder for the same**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nlabels = le.fit_transform(train_y)\nprint(labels)","execution_count":22,"outputs":[{"output_type":"stream","text":"[2 1 0 0 0 2 2 0 2 0 1 1 2 2 0 2 2 2 0 1 2 2 1 2 2 2 0 1 0 2 1 1 1 0 0 1 2\n 0 1 1 2 2 2 1 1 0 2 0 0 1 1 0 0 1 0 2 0 0 0 0 0 1 2 0 0 1 2 2 1 1 2 1 0 0\n 0 0 1 2 1 2 1 1 0 1 1 1 1 0 2 1 0 2 1 0 1 1 1 0 2 2 1 1 2 0 1 2 2 2 2 2 2\n 2 1 2 0 0 2 0 2 0 2 2 0 0 2 1 2 0 0 2 2 1 0 1 2 0 1 0 0 0 1 0 1 0 1 1 1 2\n 1 1]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"convert train_x to numpy array"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_x.values\ny = labels\nprint(X.shape)\nprint(y.shape)","execution_count":23,"outputs":[{"output_type":"stream","text":"(150, 4)\n(150,)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**Let us perform logistic regression. First we split the data into training and testing sets**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.33)\nprint('no. of training samples:',len(X_train))\nprint('no. of testing samples:',len(X_test))","execution_count":24,"outputs":[{"output_type":"stream","text":"no. of training samples: 100\nno. of testing samples: 50\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**Let us train the model using logistic regression**"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_model = LogisticRegression(multi_class='multinomial')\nlr_model.fit(X_train,y_train)","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n                   multi_class='multinomial', n_jobs=None, penalty='l2',\n                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n                   warm_start=False)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = lr_model.predict(X_test)\nprint(y_pred)","execution_count":27,"outputs":[{"output_type":"stream","text":"[0 1 2 2 1 2 2 2 0 1 0 1 0 1 1 0 2 2 1 2 0 2 0 2 2 1 0 2 1 0 2 0 0 0 0 1 1\n 1 0 1 2 1 0 2 0 1 1 1 2 2]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\nprint('test accuracy:',accuracy_score(y_test,y_pred))","execution_count":32,"outputs":[{"output_type":"stream","text":"test accuracy: 0.98\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,y_pred))","execution_count":33,"outputs":[{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        16\n           1       0.94      1.00      0.97        16\n           2       1.00      0.94      0.97        18\n\n    accuracy                           0.98        50\n   macro avg       0.98      0.98      0.98        50\nweighted avg       0.98      0.98      0.98        50\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test,y_pred))","execution_count":34,"outputs":[{"output_type":"stream","text":"[[16  0  0]\n [ 0 16  0]\n [ 0  1 17]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}