{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n#Import the Labraries for visualision \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import the Dataset\ndf = pd.read_csv(\"../input/pulsar_stars.csv\")  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets check our dataset\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#At first we Renaming columns\ndf = df.rename(columns={' Mean of the integrated profile':\"mean_profile\",\n       ' Standard deviation of the integrated profile':\"std_profile\",\n       ' Excess kurtosis of the integrated profile':\"kurtosis_profile\",\n       ' Skewness of the integrated profile':\"skewness_profile\", \n        ' Mean of the DM-SNR curve':\"mean_dmsnr_curve\",\n       ' Standard deviation of the DM-SNR curve':\"std_dmsnr_curve\",\n       ' Excess kurtosis of the DM-SNR curve':\"kurtosis_dmsnr_curve\",\n       ' Skewness of the DM-SNR curve':\"skewness_dmsnr_curve\",\n       })","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now we see the statistical inference of the dataset\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now check the if any missing value in our dataset\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now we see out target varibale\nsns.countplot(x ='target_class', data = df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now lets see the correlation by plotting heatmap\ncorr = df.corr()\ncolormap = sns.diverging_palette(220, 10, as_cmap = True)\nplt.figure(figsize = (8,6))\nsns.heatmap(corr,\n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values,\n            annot=True,fmt='.2f',linewidths=0.30,\n            cmap = colormap, linecolor='white')\nplt.title('Correlation of df Features', y = 1.05, size=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets look the correlation score\nprint (corr['target_class'].sort_values(ascending=False), '\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets see the pair plot between all variables\nsns.pairplot(df,hue = 'target_class')\nplt.title(\"pair plot for variables\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets create ML model for our dataset\nx = df.iloc[:, 0 : 8].values\ny = df.iloc[:, - 1].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Spliting the dataset to the traning and test set\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Feature Secaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.fit_transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fitting Logistic Regression to the training set\nfrom sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 0)\nclassifier.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predicting the test set result\ny_pred = classifier.predict(x_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Making the Confussion Matrix and Print Accuracy\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Logistic Regression :\")\nprint(\"Accuracy = \", accuracy)\nprint(cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let see the ROC curve\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nauc = roc_auc_score(y_test, y_pred)\nprint('AUC : %.3f' % auc)\n\nfpr, tpr, thresholds = roc_curve(y_test, y_pred)\nplt.plot([0, 1], [0, 1], linestyle = '--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.plot(fpr, tpr, marker = '.')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}