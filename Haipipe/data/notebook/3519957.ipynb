{"cells":[{"metadata":{},"cell_type":"markdown","source":" PREDICTING A PULSAR STAR"},{"metadata":{},"cell_type":"markdown","source":"Pulsars are a rare type of Neutron star that produce radio emission detectable here on Earth. They are of considerable scientific interest as probes of space-time, the inter-stellar medium, and states of matter .  Neutron stars are very dense, and have short, regular rotational periods. This produces a very precise interval between pulses that ranges from milliseconds to seconds for an individual pulsar. Pulsars are believed to be one of the candidates for the source of ultra-high-energy cosmic rays."},{"metadata":{},"cell_type":"markdown","source":"![](https://usercontent2.hubstatic.com/14277725_f520.jpg)"},{"metadata":{},"cell_type":"markdown","source":"The first pulsar was observed on November 28, 1967, by Jocelyn Bell Burnell and Antony Hewish. They observed pulses separated by 1.33 seconds that originated from the same location in the sky, and kept to sidereal time. In looking for explanations for the pulses, the short period of the pulses eliminated most astrophysical sources of radiation, such as stars, and since the pulses followed sidereal time, it could not be man-made radio frequency interference.(source=Wikipedia)"},{"metadata":{},"cell_type":"markdown","source":"In this kernel, I will explain whether a star is a pulsar star with supervised learning machine learning algorithms."},{"metadata":{},"cell_type":"markdown","source":"### **CONTENT :**\n\n1. [DATA ANALYSIS](#1)\n2. [LOGISTIC REGRESSION](#2)\n3. [K-NEAREST NEIGHBOUR(KNN) CLASSIFICATION](#3) \n4. [SUPPORT VECTOR MACHINE(SVM) CLASSIFICATION](#4)\n5. [NAIVE BAYES CLASSIFICATION](#5)\n6. [DECISION TREE CLASSIFICATION](#6)\n7. [RANDOM FOREST CLASSIFICATION](#7)\n8. [EVALUATING A CLASSIFICATION MODEL](#8)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"1\"></a> <br>\nDATA ANALYSIS "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data=pd.read_csv(\"../input/pulsar_stars.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have 9 features and looks like there are no nan values. However features names are a little bit untidy. I will change them."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data = data.rename(columns={' Mean of the integrated profile':\"mean_integrated_profile\",\n       ' Standard deviation of the integrated profile':\"std_deviation_integrated_profile\",\n       ' Excess kurtosis of the integrated profile':\"kurtosis_integrated_profile\",\n       ' Skewness of the integrated profile':\"skewness_integrated_profile\", \n        ' Mean of the DM-SNR curve':\"mean_dm_snr_curve\",\n       ' Standard deviation of the DM-SNR curve':\"std_deviation_dm_snr_curve\",\n       ' Excess kurtosis of the DM-SNR curve':\"kurtosis_dm_snr_curve\",\n       ' Skewness of the DM-SNR curve':\"skewness_dm_snr_curve\",\n       })","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false},"cell_type":"markdown","source":"Now Let's look at the 5 entries at the top of the data set"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false},"cell_type":"markdown","source":"Following heatmap shows correlation between features. \n\nThere is a high positive correlation between following features:\n- Excess kurtosis of the integrated profile - Skewness of the integrated profile (0.95)\n- Mean of the DM-SNR curve - Standard deviation of the DM-SNR curve(0.80)\n- Excess kurtosis of the DM-SNR curve - Skewness of the DM-SNR curve (0.92)\n\n\nThere is a high negative correlation between following features:\n- Mean of the integrated profile - Excess kurtosis of the integrated profile (-0.87)\n- Mean of the integrated profile - Skewness of the integrated profile (-0.74)\n- Standard deviation of the DM-SNR curve - Excess kurtosis of the DM-SNR curve (-0.81)"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f,ax=plt.subplots(figsize=(15,15))\nsns.heatmap(data.corr(),annot=True,linecolor=\"blue\",fmt=\".2f\",ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false},"cell_type":"markdown","source":"And following pairplots show correlations between features with classes"},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"g = sns.pairplot(data, hue=\"target_class\",palette=\"husl\",diag_kind = \"kde\",kind = \"scatter\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"y = data[\"target_class\"].values\nx_data = data.drop([\"target_class\"],axis=1)\nx = (x_data - np.min(x_data))/(np.max(x_data)-np.min(x_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.3,random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false},"cell_type":"markdown","source":"<a id=\"2\"></a> <br>\nLOGISTIC REGRESSION"},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(x_train,y_train)\nlr_prediction = lr.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nmse_lr=mean_squared_error(y_test,lr_prediction)\n\nfrom sklearn.metrics import confusion_matrix,classification_report\ncm_lr=confusion_matrix(y_test,lr_prediction)\ncm_lr=pd.DataFrame(cm_lr)\ncm_lr[\"total\"]=cm_lr[0]+cm_lr[1]\ncr_lr=classification_report(y_test,lr_prediction)\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"from sklearn.metrics import cohen_kappa_score\ncks_lr= cohen_kappa_score(y_test, lr_prediction)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"score_and_mse={\"model\":[\"logistic regression\"],\"Score\":[lr.score(x_test,y_test)],\"Cohen Kappa Score\":[cks_lr],\"MSE\":[mse_lr]}\nscore_and_mse=pd.DataFrame(score_and_mse)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"3\"></a> <br>\nK-NEAREST NEIGHBOUR(KNN) CLASSIFICATION "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors =13) # n_neighbors = k\nknn.fit(x_train,y_train)\nknn_prediction = knn.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_list = []\nfor each in range(1,15):\n    knn2 = KNeighborsClassifier(n_neighbors = each)\n    knn2.fit(x_train,y_train)\n    score_list.append(knn2.score(x_test,y_test))\n    \nplt.plot(range(1,15),score_list)\nplt.xlabel(\"k values\")\nplt.ylabel(\"accuracy\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mse_knn=mean_squared_error(y_test,knn_prediction)\ncm_knn=confusion_matrix(y_test,knn_prediction)\ncm_knn=pd.DataFrame(cm_knn)\ncr_knn=classification_report(y_test,knn_prediction)\ncm_knn[\"total\"]=cm_knn[0]+cm_knn[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import cohen_kappa_score\ncks_knn= cohen_kappa_score(y_test, knn_prediction)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_and_mse = score_and_mse.append({'model': \"knn classification\",\"Score\":knn.score(x_test,y_test),\"Cohen Kappa Score\":cks_knn,\"MSE\":mse_knn}, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4\"></a> <br>\nSUPPORT VECTOR MACHINE(SVM) CLASSIFICATION"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvm=SVC(random_state=1)\nsvm.fit(x_train,y_train)\nsvm_prediction=svm.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mse_svm=mean_squared_error(y_test,svm_prediction)\nsvm_cm=confusion_matrix(y_test,svm_prediction)\ncm_svm=pd.DataFrame(svm_cm)\ncm_svm[\"total\"]=cm_svm[0]+cm_svm[1]\n\ncr_svm=classification_report(y_test,svm_prediction)\ncks_svm= cohen_kappa_score(y_test, svm_prediction)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_and_mse = score_and_mse.append({'model': \"svm classification\",\"Score\":svm.score(x_test,y_test),\"Cohen Kappa Score\":cks_svm,\"MSE\":mse_svm}, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" <a id=\"5\"></a> <br>\n NAIVE BAYES CLASSIFICATION"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nnb=GaussianNB()\nnb.fit(x_train,y_train)\nprediction_nb=nb.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_mse=mean_squared_error(y_test,prediction_nb)\nnb_cm=confusion_matrix(y_test,prediction_nb)\nnb_cm=pd.DataFrame(nb_cm)\nnb_cm[\"total\"]=nb_cm[0]+nb_cm[1]\n\ncr_nb=classification_report(y_test,prediction_nb)\ncks_nb= cohen_kappa_score(y_test, prediction_nb)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_and_mse = score_and_mse.append({'model': \"naive bayes classification\",\"Score\":nb.score(x_test,y_test),\"Cohen Kappa Score\":cks_nb,\"MSE\":nb_mse}, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6\"></a> <br>\nDECISION TREE CLASSIFICATION"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndt=DecisionTreeClassifier()\ndt.fit(x_train,y_train)\nprediction_dt=dt.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt_mse=mean_squared_error(y_test,prediction_dt)\ndt_cm=confusion_matrix(y_test,prediction_dt)\ndt_cm=pd.DataFrame(dt_cm)\ndt_cm[\"total\"]=dt_cm[0]+dt_cm[1]\n\ncr_dt=classification_report(y_test,prediction_dt)\ncks_dt= cohen_kappa_score(y_test, prediction_dt)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_and_mse = score_and_mse.append({'model': \"decision tree classification\",\"Score\":dt.score(x_test,y_test),\"Cohen Kappa Score\":cks_dt, \"MSE\":dt_mse}, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"7\"></a> <br>\nRANDOM FOREST CLASSIFICATION"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf=RandomForestClassifier(n_estimators=100,random_state=1)\nrf.fit(x_train,y_train)\n\nprediction_rf=rf.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_mse=mean_squared_error(y_test,prediction_rf)\nrf_cm=confusion_matrix(y_test,prediction_rf)\nrf_cm=pd.DataFrame(rf_cm)\nrf_cm[\"total\"]=rf_cm[0]+rf_cm[1]\n\ncr_rf=classification_report(y_test,prediction_rf)\ncks_rf= cohen_kappa_score(y_test, prediction_rf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_and_mse = score_and_mse.append({'model': \"random forest classification\",\"Score\":rf.score(x_test,y_test),\"Cohen Kappa Score\":cks_rf,\"MSE\":rf_mse}, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"8\"></a> <br>\nEVALUATING A CLASSIFICATION MODEL"},{"metadata":{},"cell_type":"markdown","source":"**Classification Report**"},{"metadata":{},"cell_type":"markdown","source":"The classification report averages include : \n\n**Precision:** The ratio of the total number of correctly classified positive examples by the total number of predicted positive examples. TP/TP+FP\n\n**Recall:** The ratio of the total number of correctly classified positive examples divide to the total number of positive examples. TP/TP+FN\n\n**F-measure:** 2 x Recall x Precision / Recall+ Precision\n\n**micro average:** averaging the total true positives, false negatives and false positives, \n\n**macro average:** averaging the unweighted mean per label, \n\n**weighted average:** averaging the support-weighted mean per label "},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Classification report for Logistic Regression: \\n',cr_lr)\nprint('Classification report for KNN Classification: \\n',cr_knn)\nprint('Classification report for SVM Classification: \\n',cr_svm)\nprint('Classification report for Naive Bayes Classification: \\n',cr_nb)\nprint('Classification report for Decision Tree Classification: \\n',cr_dt)\nprint('Classification report for Random Forest Classification: \\n',cr_rf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Confusion Matrix**"},{"metadata":{},"cell_type":"markdown","source":"A confusion matrix is a summary of prediction results on a classification problem.\n\nPositive (P) : Observation is positive (for example: is a Pulse Star).\n\nNegative (N) : Observation is not positive (for example: is not a Pulse Star).\n\nTrue Positive (TP) : Observation is positive, and is predicted to be positive.\n\nFalse Negative (FN) : Observation is positive, but is predicted negative.\n\nTrue Negative (TN) : Observation is negative, and is predicted to be negative.\n\nFalse Positive (FP) : Observation is negative, but is predicted positive."},{"metadata":{},"cell_type":"markdown","source":"\n\n![](http://rasbt.github.io/mlxtend/user_guide/evaluate/confusion_matrix_files/confusion_matrix_1.png)"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f, axes = plt.subplots(2, 3,figsize=(18,12))\ng1 = sns.heatmap(cm_lr,annot=True,fmt=\".1f\",cmap=\"flag\",cbar=False,ax=axes[0,0])\ng1.set_ylabel('y_true')\ng1.set_xlabel('y_head')\ng1.set_title(\"Logistic Regression\")\ng2 = sns.heatmap(cm_knn,annot=True,fmt=\".1f\",cmap=\"flag\",cbar=False,ax=axes[0,1])\ng2.set_ylabel('y_true')\ng2.set_xlabel('y_head')\ng2.set_title(\"KNN Classification\")\ng3 = sns.heatmap(cm_svm,annot=True,fmt=\".1f\",cmap=\"flag\",ax=axes[0,2])\ng3.set_ylabel('y_true')\ng3.set_xlabel('y_head')\ng3.set_title(\"SVM Classification\")\ng4 = sns.heatmap(nb_cm,annot=True,fmt=\".1f\",cmap=\"flag\",cbar=False,ax=axes[1,0])\ng4.set_ylabel('y_true')\ng4.set_xlabel('y_head')\ng4.set_title(\"Naive Bayes Classification\")\ng5 = sns.heatmap(dt_cm,annot=True,fmt=\".1f\",cmap=\"flag\",cbar=False,ax=axes[1,1])\ng5.set_ylabel('y_true')\ng5.set_xlabel('y_head')\ng5.set_title(\"Decision Tree Classification\")\ng6 = sns.heatmap(rf_cm,annot=True,fmt=\".1f\",cmap=\"flag\",ax=axes[1,2])\ng6.set_ylabel('y_true')\ng6.set_xlabel('y_head')\ng6.set_title(\"Random Forest Classification\")\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Receiver Operating Characteristic(ROC) Curve**"},{"metadata":{},"cell_type":"markdown","source":"In a Receiver Operating Characteristic (ROC) curve the true positive rate (Sensitivity) is plotted in function of the false positive rate (100-Specificity) for different cut-off points. \n\nEach point on the ROC curve represents a sensitivity/specificity pair corresponding to a particular decision threshold.\n\nA test with perfect discrimination (no overlap in the two distributions) has a ROC curve that passes through the upper left corner (100% sensitivity, 100% specificity). \n\nTherefore the closer the ROC curve is to the upper left corner, the higher the overall accuracy of the test (Zweig & Campbell, 1993)."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfpr_lr, tpr_lr, thresholds = roc_curve(y_test, lr_prediction)\nplt.plot([0, 1], [0, 1], 'k--',color=\"grey\")\nplt.plot(fpr_lr, tpr_lr,color=\"red\")\nplt.title('Logistic Regression')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Accuracy (Score) **"},{"metadata":{},"cell_type":"markdown","source":"It is the ratio of number of correct predictions to the total number of input samples.\n\nAccuracy= Number of Correct Predictions/ Total Number of Predictions Made"},{"metadata":{},"cell_type":"markdown","source":"**Cohen Kappa Score**"},{"metadata":{},"cell_type":"markdown","source":"Kappa is similar to Accuracy score, but it takes into account the accuracy that would have happened anyway through random predictions.\n\nIt is a measure of how well the classifier actually performs. In other words, if there is a big difference between accuracy and null error rate, a model will have a high Kappa score.\n\n\nCohen Kappa only serves to make comparisons between two classifiers, if there are more than two classifiers, Fleiss's Kappa is used.\n\nKappa = (Observed Accuracy - Expected Accuracy) / (1 - Expected Accuracy)"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Mean Squared Error(MSE)**"},{"metadata":{},"cell_type":"markdown","source":"Mean Squared Error(MSE) is quite similar to Mean Absolute Error, the only difference being that MSE takes the average of the square of the difference between the original values and the predicted values."},{"metadata":{"trusted":true},"cell_type":"code","source":"score_and_mse","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}